
import pandas as pd
import os
import shutil
import re
import glob
import sys
from datetime import datetime

# ==========================================
# é…ç½®åŒºåŸŸ
# ==========================================
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
SOURCE_FILE_PATH = os.path.join(BASE_DIR, 'å’¸é±¼åº¦ç›˜æº.xlsx')  # å®Œæ•´ç‰ˆ (å«é“¾æ¥)
PUBLIC_FILE_PATH = os.path.join(BASE_DIR, 'å’¸é±¼åº¦ç›˜.xlsx')   # å…¬å¼€ç‰ˆ (æ— é“¾æ¥)

def clear_screen():
    os.system('cls' if os.name == 'nt' else 'clear')

# ==========================================
# è¾…åŠ©å‡½æ•°: æ™ºèƒ½æŸ¥æ‰¾æ— æ•ˆæ–‡ä»¶
# ==========================================
def find_invalid_file():
    txt_files = glob.glob(os.path.join(BASE_DIR, '*.txt'))
    if not txt_files:
        return None
    if len(txt_files) == 1:
        return txt_files[0]
    print("\nå‘ç°å¤šä¸ª TXT æ–‡ä»¶:")
    for i, f in enumerate(txt_files):
        print(f"{i+1}. {os.path.basename(f)}")
    while True:
        choice = input("\nè¯·é€‰æ‹©åŒ…å«æ— æ•ˆé“¾æ¥çš„æ–‡ä»¶ç¼–å· (è¾“å…¥0å–æ¶ˆ): ").strip()
        if choice == '0':
            return None
        if choice.isdigit() and 1 <= int(choice) <= len(txt_files):
            return txt_files[int(choice)-1]
        print("æ— æ•ˆè¾“å…¥ï¼Œè¯·é‡æ–°è¾“å…¥")

def normalize_link(text):
    if not isinstance(text, str): return str(text)
    m = re.search(r'(https?://[\w\-\./?=&%]+)', text)
    return m.group(1) if m else text.strip()

def load_invalid_urls(file_path):
    if not file_path: return set()
    encodings = ['utf-8', 'gb18030', 'gbk']
    content = []
    for enc in encodings:
        try:
            with open(file_path, 'r', encoding=enc) as f:
                content = f.readlines()
            break
        except UnicodeDecodeError:
            continue
            
    invalid_urls = set()
    for line in content:
        match = re.search(r'(https?://[\w\-\./?=&%]+)', line)
        if match:
            url = match.group(1)
            if 'é“¾æ¥' in url: url = url.split('é“¾æ¥')[0]
            invalid_urls.add(url)
    return invalid_urls

# ==========================================
# åŠŸèƒ½1: è‡ªåŠ¨ç»´æŠ¤ (é’ˆå¯¹ 'å’¸é±¼åº¦ç›˜æº.xlsx')
# ==========================================
def clean_source_file():
    print("\n" + "="*40)
    print("      æ‰§è¡Œè‡ªåŠ¨ç»´æŠ¤ (ä»…å¤„ç†æºæ–‡ä»¶)")
    print("="*40)
    print(f"ç›®æ ‡æ–‡ä»¶: {os.path.basename(SOURCE_FILE_PATH)} (ä¿ç•™å®Œæ•´åˆ—)")
    
    invalid_file_path = find_invalid_file()
    if not invalid_file_path:
        print("âŒ é”™è¯¯: æœªæ‰¾åˆ°é»‘åå•æ–‡ä»¶")
        return

    print(f"ğŸ“„ é»‘åå•: {os.path.basename(invalid_file_path)}")

    
    # 1. Parse Invalid Links
    print("--- 1. è§£ææ— æ•ˆé“¾æ¥ ---")
    invalid_urls = load_invalid_urls(invalid_file_path)
    print(f"   æå–åˆ° {len(invalid_urls)} æ¡éœ€ç§»é™¤çš„é“¾æ¥ã€‚")

    # 2. Process
    print(f"\n--- 2. æ¸…æ´—æ–‡ä»¶: {os.path.basename(SOURCE_FILE_PATH)} ---")
    try:
        # Check if file exists
        if not os.path.exists(SOURCE_FILE_PATH):
             print(f"âŒ æºæ–‡ä»¶ä¸å­˜åœ¨: {SOURCE_FILE_PATH}")
             return

        all_sheets = pd.read_excel(SOURCE_FILE_PATH, sheet_name=None)
    except Exception as e:
        print(f"   è¯»å–å¤±è´¥: {e}")
        return

    cleaned_sheets = {}
    total_removed = 0
    link_col_name = 'é“¾æ¥'

    for sheet_name, df in all_sheets.items():
        if link_col_name not in df.columns:
            cleaned_sheets[sheet_name] = df
            continue
            
        initial_count = len(df)
            
        excel_links = df[link_col_name].apply(normalize_link)
        mask = ~excel_links.isin(invalid_urls)
        
        df_cleaned = df[mask]
        removed = initial_count - len(df_cleaned)
        total_removed += removed
        cleaned_sheets[sheet_name] = df_cleaned

    # Save
    if total_removed > 0:
        print("\n--- 3. ä¿å­˜æ›´æ”¹ ---")
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        new_backup = os.path.join(BASE_DIR, f'å’¸é±¼åº¦ç›˜æº_backup_{timestamp}.xlsx')
        try:
            shutil.copy2(SOURCE_FILE_PATH, new_backup)
            print(f"   å·²å¤‡ä»½æºæ–‡ä»¶è‡³: {os.path.basename(new_backup)}")
            
            with pd.ExcelWriter(SOURCE_FILE_PATH, engine='openpyxl') as writer:
                for sheet_name, df in cleaned_sheets.items():
                    df.to_excel(writer, sheet_name=sheet_name, index=False)
            print(f"   âœ… 'å’¸é±¼åº¦ç›˜æº.xlsx' å·²æ›´æ–° (ç§»é™¤ {total_removed} è¡Œ)")
        except Exception as e:
            print(f"   âŒ ä¿å­˜å¤±è´¥: {e}")
    else:
        print("\n   âœ… æºæ–‡ä»¶æ— éœ€ä¿®æ”¹ (æœªå‘ç°å¤±æ•ˆé“¾æ¥)")

# ==========================================
# åŠŸèƒ½2: èµ„æºæŸ¥è¯¢ (åŸºäº 'å’¸é±¼åº¦ç›˜æº.xlsx')
# ==========================================
def search_resources():
    print("\n" + "="*40)
    print("      èµ„æºæŸ¥è¯¢ (åŸºäºå®Œæ•´æºæ–‡ä»¶)")
    print("="*40)
    
    # Pre-check: Load invalid links if any
    invalid_urls = set()
    print("æ£€æµ‹åˆ°å¤±æ•ˆé“¾æ¥åº“æ–‡ä»¶(.txt):")
    invalid_file = find_invalid_file()
    if invalid_file:
        print(f"æ­£åœ¨åŠ è½½å¤±æ•ˆåº“: {os.path.basename(invalid_file)}...")
        invalid_urls = load_invalid_urls(invalid_file)
        print(f"âœ… å·²åŠ è½½ {len(invalid_urls)} æ¡å¤±æ•ˆé“¾æ¥è§„åˆ™ã€‚")
    else:
        print("æœªåŠ è½½å¤±æ•ˆåº“ï¼Œè·³è¿‡æœ‰æ•ˆæ€§æ£€æŸ¥ã€‚")

    try:
        all_sheets = pd.read_excel(SOURCE_FILE_PATH, sheet_name=None)
    except Exception as e:
        print(f"è¯»å–æºæ–‡ä»¶å¤±è´¥: {e}")
        return

    data_index = {}
    for sheet_name, df in all_sheets.items():
        df.columns = [str(c).replace('\n', '').strip() for c in df.columns]
        col_map = {}
        for c in df.columns:
            if 'é“¾æ¥' in c and 'tg' not in c: col_map['link'] = c
            elif 'è§£å‹ç ' in c or ('å¯†ç ' in c and 'æå–ç ' not in c): col_map['unzip'] = c
            elif 'å¤‡æ³¨' in c: col_map['note'] = c
            elif 'æå–ç ' in c: col_map['pwd'] = c
            elif 'åºå·' in c: col_map['id'] = c
        
        if 'id' not in col_map: continue
        
        sheet_index = {}
        for idx, row in df.iterrows():
            raw_id = row[col_map['id']]
            if pd.isna(raw_id): continue
            try:
                if isinstance(raw_id, float) and raw_id.is_integer():
                    serial = str(int(raw_id))
                else:
                    serial = str(raw_id).strip()
                    if serial.endswith(".0"): serial = serial[:-2]
            except:
                serial = str(raw_id).strip()

            item = {
                'link': row.get(col_map.get('link'), 'N/A'),
                'pwd': row.get(col_map.get('pwd'), 'NaN'),
                'unzip': row.get(col_map.get('unzip'), 'æ— '),
                'note': row.get(col_map.get('note'), '')
            }
            sheet_index[serial] = item
        data_index[sheet_name] = sheet_index

    print(f"æ•°æ®åŠ è½½å®Œæ¯•ã€‚å¯ç”¨é¡µå·: {list(data_index.keys())}")
    print("è¾“å…¥æ ¼å¼1: é¡µå· åºå· (å¦‚: A 1)")
    print("è¾“å…¥æ ¼å¼2: é¡µå·(åºå·1.åºå·2...) (å¦‚: a(1.2.3)) - æ‰¹é‡å¯¼å‡ºç»“æœ")
    print("è¾“å…¥ q é€€å‡º")
    print("-" * 50)

    while True:
        choice = input("\næŸ¥è¯¢ > ").strip()
        if choice.lower() in ('q', 'quit', 'exit'): break
        if not choice: continue
        
        # Check for batch pattern: e.g. a(1.2.3) or aï¼ˆ1.2.3ï¼‰
        batch_match = re.match(r'^(.+?)[(ï¼ˆ]([\d\.]+)[)ï¼‰]$', choice)
        if batch_match:
            sheet_input = batch_match.group(1).strip()
            ids_str = batch_match.group(2)
            
            # Find sheet
            found_sheet = next((s for s in data_index if s.lower() == sheet_input.lower()), None)
            if not found_sheet:
                print(f"  [âŒ] æœªæ‰¾åˆ°é¡µå·: {sheet_input}")
                continue
                
            # Parse IDs
            id_list = [x.strip() for x in ids_str.split('.') if x.strip()]
            
            results = []
            not_found = []
            
            print(f"\næ­£åœ¨æ‰¹é‡æŸ¥æ‰¾ {found_sheet} ä¸­çš„ {len(id_list)} ä¸ªæ¡ç›®...")
            
            for sn in id_list:
                item = data_index[found_sheet].get(str(sn))
                if item:
                    full_link = str(item['link'])
                    clean_link = normalize_link(full_link)
                    
                    # Validity Check
                    if invalid_urls and clean_link in invalid_urls:
                        print(f"  âŒ å¤±æ•ˆ: {sn} [å‘½ä¸­é»‘åå•]")
                        not_found.append(f"{sn}(å¤±æ•ˆ)")
                        continue

                    if str(item['pwd']) != 'nan' and str(item['pwd']) not in full_link:
                        full_link += f" (æå–ç : {item['pwd']})"
                    
                    res_str = f"[ID: {sn}]\né“¾æ¥: {full_link}\nè§£å‹: {item['unzip']}\nå¤‡æ³¨: {item['note']}\n"
                    results.append(res_str)
                    print(f"  âœ… æ‰¾åˆ°: {sn}")
                else:
                    not_found.append(sn)
                    print(f"  âŒ æœªæ‰¾åˆ°: {sn}")
            
            # Save to file
            if results:
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                filename = f"search_results_{found_sheet}_{timestamp}.txt"
                filepath = os.path.join(BASE_DIR, filename)
                
                try:
                    with open(filepath, 'w', encoding='utf-8') as f:
                        f.write(f"èµ„æºæœç´¢ç»“æœ: {found_sheet}\n")
                        f.write(f"ç”Ÿæˆçš„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                        f.write("=" * 30 + "\n\n")
                        f.write("\n".join(results))
                        if not_found:
                            f.write("\n" + "=" * 30 + "\n")
                            f.write(f"æœªæ‰¾åˆ°/å¤±æ•ˆåºå· ({len(not_found)}ä¸ª):\n")
                            f.write(", ".join(not_found))
                    
                    print(f"\nğŸ“„ ç»“æœå·²ä¿å­˜è‡³: {filename}")
                except Exception as e:
                    print(f"âŒ ä¿å­˜å¤±è´¥: {e}")

                if not_found:
                    print(f"âš ï¸  æœªæ‰¾åˆ°/å¤±æ•ˆ IDs: {', '.join(not_found)}")
            else:
                print("\nâš ï¸  æœªæ‰¾åˆ°ä»»ä½•åŒ¹é…é¡¹ã€‚")
            
            continue

        parts = choice.replace(',', ' ').replace('-', ' ').replace(':', ' ').split()
        if len(parts) % 2 != 0:
            print("âŒ æ ¼å¼é”™è¯¯ã€‚")
            continue
            
        for i in range(0, len(parts), 2):
            pg, sn = parts[i], parts[i+1]
            found_sheet = next((s for s in data_index if s.lower() == pg.lower()), None)
            if not found_sheet:
                print(f"  [âŒ] æœªæ‰¾åˆ°é¡µå· {pg}")
                continue
            item = data_index[found_sheet].get(str(sn))
            if item:
                full_link = str(item['link'])
                if str(item['pwd']) != 'nan' and str(item['pwd']) not in full_link:
                    full_link += f" (æå–ç : {item['pwd']})"
                print(f"  [âœ… {found_sheet}-{sn}]")
                print(f"      é“¾æ¥: {full_link}")
                print(f"      è§£å‹: {item['unzip']}")
                print(f"      å¤‡æ³¨: {item['note']}")
            else:
                print(f"  [âŒ] {found_sheet}-{sn} ä¸å­˜åœ¨")

# ==========================================
# åŠŸèƒ½3: ç”Ÿæˆå…¬å¼€ç‰ˆ (å’¸é±¼åº¦ç›˜.xlsx)
# ==========================================
def generate_public_file():
    print("\n" + "="*40)
    print("      ç”Ÿæˆå…¬å¼€åˆ†äº«ç‰ˆ")
    print("="*40)
    
    # æ˜ç¡®å±•ç¤ºè¾“å…¥è¾“å‡º
    print(f"1. è¯»å–æºæ–‡ä»¶: {os.path.basename(SOURCE_FILE_PATH)} (ä¿æŒä¸å˜)")
    print(f"2. è¾“å‡ºç›®æ ‡:   {os.path.basename(PUBLIC_FILE_PATH)} (å°†è¢«è¦†ç›–)")
    
    if not os.path.exists(SOURCE_FILE_PATH):
        print(f"âŒ é”™è¯¯: æºæ–‡ä»¶ä¸å­˜åœ¨!")
        return

    print("\næ­£åœ¨å¤„ç†æ•°æ®...")
    try:
        all_sheets = pd.read_excel(SOURCE_FILE_PATH, sheet_name=None)
    except Exception as e:
        print(f"è¯»å–å¤±è´¥: {e}")
        return

    columns_to_drop = ['tgé“¾æ¥', 'é“¾æ¥']
    processed_sheets = {}
    
    for sheet_name, df in all_sheets.items():
        df.columns = [str(c).replace('\n', '').strip() for c in df.columns]
        
        # Identify columns to drop
        drop_list = [c for c in df.columns if c in columns_to_drop]
        
        if drop_list:
            processed_sheets[sheet_name] = df.drop(columns=drop_list)
            print(f"   Sheet '{sheet_name}': å·²å‰”é™¤ {drop_list}")
        else:
            processed_sheets[sheet_name] = df
            print(f"   Sheet '{sheet_name}': æ— æ•æ„Ÿåˆ—ï¼Œä¿ç•™åŸæ ·")

    print(f"\næ­£åœ¨å†™å…¥æ–‡ä»¶: {os.path.basename(PUBLIC_FILE_PATH)} ...")
    try:
        with pd.ExcelWriter(PUBLIC_FILE_PATH, engine='openpyxl') as writer:
            for sheet_name, df in processed_sheets.items():
                df.to_excel(writer, sheet_name=sheet_name, index=False)
        print("âœ… å¯¼å‡ºæˆåŠŸï¼")
        print("   è¯¥æ–‡ä»¶å·²ä¸åŒ…å« 'tgé“¾æ¥' å’Œ 'ç™¾åº¦ç½‘ç›˜é“¾æ¥' åˆ—ã€‚")
    except Exception as e:
        print(f"âŒ å†™å…¥å¤±è´¥: {e}")

# ==========================================
# ä¸»ç¨‹åºå…¥å£
# ==========================================
def main_menu():
    while True:
        clear_screen()
        print("\n" + "="*40)
        print("      å’¸é±¼åº¦ç›˜æº - ç»¼åˆç®¡ç†å·¥å…·")
        print("="*40)
        print(" å½“å‰æºæ–‡ä»¶: å’¸é±¼åº¦ç›˜æº.xlsx")
        print("-" * 40)
        print("1. è‡ªåŠ¨æ¸…æ´—ç»´æŠ¤ (ä»…æ›´æ–°æºæ–‡ä»¶)")
        print("2. èµ„æºæŸ¥è¯¢ (ä½¿ç”¨æºæ–‡ä»¶)")
        print("3. ç”Ÿæˆå…¬å¼€ç‰ˆ (å¦å­˜ä¸º 'å’¸é±¼åº¦ç›˜.xlsx')")
        print("q. é€€å‡ºç¨‹åº")
        print("-" * 40)
        
        choice = input("è¯·é€‰æ‹©åŠŸèƒ½: ").strip().lower()
        
        if choice == '1':
            clean_source_file()
            input("\næŒ‰å›è½¦é”®è¿”å›ä¸»èœå•...")
        elif choice == '2':
            search_resources()
        elif choice == '3':
            generate_public_file()
            input("\næŒ‰å›è½¦é”®è¿”å›ä¸»èœå•...")
        elif choice in ('q', 'quit', 'exit'):
            print("å†è§ï¼")
            break
        else:
            print("æ— æ•ˆè¾“å…¥")
            input("æŒ‰å›è½¦é”®ç»§ç»­...")

if __name__ == "__main__":
    main_menu()
