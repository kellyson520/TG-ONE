import logging
import traceback
import os
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, Any

from services.network.bot_heartbeat import get_heartbeat
from services.dedup.engine import smart_deduplicator
from core.helpers.realtime_stats import realtime_stats_cache

logger = logging.getLogger(__name__)

class AnalyticsService:
    """
    æ•°æ®åˆ†ææœåŠ¡
    è´Ÿè´£èšåˆæ¥è‡ªå„ä¸ª Repository å’Œå·¥å…·ç±»çš„ç»Ÿè®¡ä¿¡æ¯
    """
    
    def __init__(self, container=None):
        self._container = container

    @property
    def container(self):
        if self._container:
            return self._container
        from core.container import container
        return container

    def _get_dir_size(self, path: Path) -> int:
        """é€’å½’è·å–ç›®å½•å¤§å° (Bytes)"""
        total = 0
        try:
            if not path.exists():
                return 0
            for entry in os.scandir(path):
                if entry.is_file():
                    total += entry.stat().st_size
                elif entry.is_dir():
                    total += self._get_dir_size(Path(entry.path))
        except Exception as e:
            logger.debug(f"è®¡ç®—ç›®å½•å¤§å°æ—¶è·³è¿‡ {path}: {e}")
        return total

    async def get_data_size_mb(self) -> float:
        """è·å–æ•°æ®ç›®å½•æ€»å¤§å° (MB)"""
        try:
            from core.config import settings
            # ç»Ÿä¸€ä½¿ç”¨ DATA_ROOT
            data_root = Path(settings.DATA_ROOT)
            total_bytes = self._get_dir_size(data_root)
            return round(total_bytes / (1024 * 1024), 2)
        except Exception as e:
            logger.error(f"è·å–æ•°æ®ç›®å½•å¤§å°å¤±è´¥: {e}")
            return 0.0

    async def get_analytics_overview(self) -> Dict[str, Any]:
        """è·å–ç³»ç»Ÿç»Ÿè®¡æ€»è§ˆ"""
        try:
            # 1. è·å–è§„åˆ™ç»Ÿè®¡
            rule_stats = await self.container.task_repo.get_rule_stats()
            overview = {
                'total_rules': rule_stats.get('total_rules', 0),
                'active_rules': rule_stats.get('active_rules', 0),
                'total_chats': rule_stats.get('total_chats', 0)
            }
            
            # 2. è·å–è½¬å‘ç»Ÿè®¡ (ä» ForwardService è·å–ä»Šæ—¥ç»Ÿè®¡)
            forward_stats = {'total_forwards': 0}
            try:
                from services.forward_service import forward_service
                fs = await forward_service.get_forward_stats()
                if isinstance(fs, dict):
                    ft = int(((fs.get('today') or {}).get('total_forwards') or 0))
                    if ft >= 0:
                        forward_stats = {'total_forwards': ft}
            except Exception as e:
                logger.warning(f"AnalyticsService è·å–è½¬å‘ç»Ÿè®¡å¤±è´¥: {e}")
            
            # 3. è·å–å»é‡ç»Ÿè®¡
            dedup_stats = {'cached_signatures': 0}
            try:
                dedup = smart_deduplicator.get_stats()
                dedup_stats = {'cached_signatures': int(dedup.get('cached_signatures', 0))}
            except Exception as e:
                logger.error(f"AnalyticsService è·å–å»é‡ç»Ÿè®¡å¤±è´¥: {e}")
                
            # 4. è·å– HLL ç‹¬ç«‹æ¶ˆæ¯ä¼°è®¡
            hll_stats = {'unique_messages_estimate': 0}
            try:
                from core.algorithms.hll import GlobalHLL
                hll = GlobalHLL.get_hll("unique_messages_today")
                hll_stats = {'unique_messages_estimate': hll.count()}
            except Exception as e:
                logger.warning(f"AnalyticsService è·å– HLL ç»Ÿè®¡å¤±è´¥: {e}")

            # 5. ç»„åˆæœ€ç»ˆæ•°æ®ä»¥å¯¹é½ Renderer éœ€æ±‚
            # è·å–æ´»è·ƒåˆ†ææ•°æ®(å¯èƒ½éœ€è¦ä» get_detailed_stats ç»„åˆéƒ¨åˆ†)
            detailed = await self.get_detailed_stats(days=1)
            
            # è·å–æ˜¨æ—¥ç»Ÿè®¡
            yesterday_str = (datetime.now() - timedelta(days=1)).strftime("%Y-%m-%d")
            yesterday_summary = await self.get_daily_summary(yesterday_str)
            yesterday_total = yesterday_summary.get('total_forwards', 0)
            
            # å¼ºåŒ– overview å­—æ®µä»¥å¯¹é½ main_menu_renderer.py:140
            system_status = await self.get_system_status()
            enriched_overview = {
                'total_rules': overview.get('total_rules', 0),
                'active_rules': overview.get('active_rules', 0),
                'total_chats': overview.get('total_chats', 0),
                'today_total': forward_stats.get('total_forwards', 0),
                'yesterday_total': yesterday_total,
                'data_size_mb': system_status.get('system_resources', {}).get('total_size_mb', 0.0),
                'trend': {
                    'text': 'ğŸ“ˆ ç¨³æ­¥å¢é•¿' if forward_stats.get('total_forwards', 0) > yesterday_total else 'â¸ï¸ å¾…æœºä¸­',
                    'percentage': round((forward_stats.get('total_forwards', 0) - yesterday_total) / yesterday_total * 100, 1) if yesterday_total > 0 else 0
                },
                'hourly': detailed.get('time_analysis', {}).get('hourly_today', {})
            }

            return {
                'overview': enriched_overview,
                'forward_stats': forward_stats,
                'dedup_stats': dedup_stats,
                'hll_stats': hll_stats,
                'top_type': next(iter(detailed.get('type_distribution', [])), None),
                'top_chat': next(iter(detailed.get('top_chats', [])), None),
                'top_rule': next(iter(detailed.get('top_rules', [])), None)
            }
        except Exception as e:
            logger.error(f"get_analytics_overview å¤±è´¥: {e}\n{traceback.format_exc()}")
            return {
                'overview': {'total_rules': 0, 'active_rules': 0, 'total_chats': 0},
                'forward_stats': {'total_forwards': 0},
                'dedup_stats': {'cached_signatures': 0},
                'error': str(e)
            }

    async def get_system_status(self) -> Dict[str, Any]:
        """è·å–å„é¡¹æœåŠ¡è¿è¡ŒçŠ¶æ€ (ä¸ºç³»ç»Ÿä¸­å¿ƒé¡µé¢æä¾›çœŸå®æ•°æ®)"""
        try:
            # 1. åŸºç¡€èµ„æºçŠ¶æ€ (CPU/MEM/Uptime)
            import psutil
            import time
            from datetime import datetime
            
            # è¿è¡Œæ—¶é—´
            boot_time = datetime.fromtimestamp(psutil.boot_time())
            uptime_hours = (datetime.now() - boot_time).total_seconds() / 3600
            
            # æ•°æ®å¤§å°
            total_size_mb = await self.get_data_size_mb()
            
            system_resources = {
                "cpu_percent": psutil.cpu_percent(interval=0.1),
                "memory_percent": psutil.virtual_memory().percent,
                "uptime_hours": round(uptime_hours, 1),
                "total_size_mb": total_size_mb,
                "status": "healthy" if psutil.cpu_percent() < 80 else "warning"
            }

            # 2. é…ç½®ä¸è¿è¡ŒçŠ¶æ€
            db_status = "running"
            from core.container import container
            try:
                async with container.db.session() as session:
                    from sqlalchemy import select, func
                    from models.models import ForwardRule, RuleLog
                    
                    # è½¬å‘è§„åˆ™ç»Ÿè®¡
                    total_rules = (await session.execute(select(func.count(ForwardRule.id)))).scalar() or 0
                    active_rules = (await session.execute(select(func.count(ForwardRule.id)).where(ForwardRule.enable_rule == True))).scalar() or 0
                    forward_rules_status = f"{active_rules}/{total_rules} å¯ç”¨"
                    
                    # æ•°æ®è®°å½•çŠ¶æ€ (æ£€æŸ¥æœ€è¿‘æ˜¯å¦æœ‰æ—¥å¿—æ¡ç›®)
                    recent_logs = (await session.execute(select(func.count(RuleLog.id)).limit(1))).scalar() or 0
                    data_recording_status = "âœ… è¿è¡Œä¸­" if recent_logs > 0 else "ğŸ’¤ å¾…æœº"
            except Exception as e:
                logger.error(f"AnalyticsService æ•°æ®åº“æ£€æŸ¥å¤±è´¥: {e}")
                db_status = "unhealthy"
                forward_rules_status = "æœªçŸ¥"
                data_recording_status = "æœªçŸ¥"

            # 3. æ™ºèƒ½å»é‡çŠ¶æ€
            dedup_conf = smart_deduplicator.config or {}
            dedup_enabled = dedup_conf.get('enable_time_window') or dedup_conf.get('enable_content_hash')
            smart_dedup_status = "âœ… å·²å¼€å¯" if dedup_enabled else "âŒ å·²å…³é—­"

            # 4. Bot/User Client çŠ¶æ€
            bot_connected = False
            user_connected = False
            try:
                if self.container.bot_client:
                    bot_connected = self.container.bot_client.is_connected()
                if self.container.user_client:
                    user_connected = self.container.user_client.is_connected()
            except Exception as e:
                logger.warning(f"è·å– Client è¿æ¥çŠ¶æ€å¤±è´¥: {e}")

            # 5. ç»„è£…è¿”å›æ•°æ® (å¯¹é½ MainMenuRenderer.render_system_hub)
            return {
                "system_resources": system_resources,
                "config_status": {
                    "forward_rules": forward_rules_status,
                    "smart_dedup": smart_dedup_status,
                    "data_recording": data_recording_status
                },
                "overall_status": "healthy" if system_resources["status"] == "healthy" and db_status == "running" else "warning",
                "db": db_status, 
                "bot": "running" if bot_connected else "stopped",
                "user": "running" if user_connected else "stopped",
                "dedup": "running" if dedup_enabled else "stopped"
            }
        except Exception as e:
            logger.error(f"get_system_status å¤±è´¥: {e}")
            return {
                "system_resources": {"cpu_percent": 0, "memory_percent": 0, "status": "unknown"},
                "config_status": {
                    "forward_rules": "æœªçŸ¥",
                    "smart_dedup": "æœªçŸ¥",
                    "data_recording": "æœªçŸ¥"
                },
                "overall_status": "unknown"
            }

    async def get_performance_metrics(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½æŒ‡æ ‡å’Œèµ„æºå ç”¨"""
        try:
            # è·å–å®æ—¶ç»Ÿè®¡æ•°æ®

            # è·å–ç³»ç»Ÿèµ„æºç»Ÿè®¡
            system_stats = await realtime_stats_cache.get_system_stats(
                force_refresh=True
            )
            system_resources = system_stats.get("system_resources", {})

            # è·å–è½¬å‘ç»Ÿè®¡ä»¥è®¡ç®—æ€§èƒ½æŒ‡æ ‡
            forward_stats = await realtime_stats_cache.get_forward_stats()
            today_stats = forward_stats.get("today", {})

            # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
            success_rate = 100.0
            if "total_forwards" in today_stats and today_stats["total_forwards"] > 0:
                errors = today_stats.get("error_count", 0)
                success_rate = (
                    (today_stats["total_forwards"] - errors)
                    / today_stats["total_forwards"]
                ) * 100

            # è·å–é˜Ÿåˆ—çŠ¶æ€
            active_queues = 0
            pending_tasks = 0
            try:
                queue_status = await self.container.task_repo.get_queue_status()
                active_queues = queue_status.get("active_queues", 0)
                pending_tasks = queue_status.get("pending_tasks", 0)
            except Exception as e:
                logger.warning(f'å·²å¿½ç•¥é¢„æœŸå†…çš„å¼‚å¸¸: {e}' if 'e' in locals() else 'å·²å¿½ç•¥é™é»˜å¼‚å¸¸')

            return {
                "system_resources": {
                    "cpu_percent": system_resources.get("cpu_percent", 0),
                    "memory_percent": system_resources.get("memory_percent", 0),
                    "status": "healthy"
                    if system_resources.get("cpu_percent", 0) < 80
                    else "warning",
                },
                "performance": {
                    "success_rate": success_rate,
                    "avg_response_time": 0.5,  # æ¨¡æ‹Ÿå€¼
                    "current_tps": 12.5,  # æ¨¡æ‹Ÿå€¼
                    "status": "good" if success_rate > 90 else "poor",
                },
                "queue_status": {
                    "active_queues": active_queues,
                    "pending_tasks": pending_tasks,
                    "error_rate": f"{(100-success_rate):.1f}%",
                },
            }
        except Exception as e:
            logger.error(f"get_performance_metrics å¤±è´¥: {e}")
            return {
                "system_resources": {"cpu_percent": 0, "memory_percent": 0},
                "performance": {"success_rate": 0},
                "queue_status": {"active_queues": 0},
            }

    async def get_daily_summary(self, date_str: str) -> Dict[str, Any]:
        """è·å–æŒ‡å®šæ—¥æœŸçš„æ¯æ—¥æ±‡æ€» (ä»æ•°æ®åº“è·å–)"""
        try:
            from sqlalchemy import select, func
            from models.models import RuleLog, ChatStatistics

            async with self.container.db.session() as session:
                # 1. ç»Ÿè®¡æ€»è½¬å‘æ•°å’Œé”™è¯¯æ•° (ä» RuleLog)
                stats_stmt = (
                    select(
                        func.count(RuleLog.id).label('total'),
                        func.sum(RuleLog.action == 'error').label('errors')
                    )
                    .where(func.strftime('%Y-%m-%d', RuleLog.created_at) == date_str)
                )
                stats_res = await session.execute(stats_stmt)
                row = stats_res.first()
                total = row.total if row and row.total else 0
                errors = row.errors if row and row.errors else 0

                # 2. ç»Ÿè®¡æ´»è·ƒèŠå¤© (ä» ChatStatistics)
                chats_stmt = (
                    select(ChatStatistics)
                    .where(ChatStatistics.date == date_str)
                    .order_by(ChatStatistics.forward_count.desc())
                )
                chats_res = await session.execute(chats_stmt)
                chats_data = chats_res.scalars().all()
                
                chats_dict = {str(c.chat_id): c.forward_count for c in chats_data}
                
                return {
                    'total_forwards': total,
                    'error_count': errors,
                    'chats': chats_dict,
                    'active_chats': len(chats_dict),
                    'date': date_str
                }
        except Exception as e:
            logger.error(f"get_daily_summary å¤±è´¥ for {date_str}: {e}")
            return {'total_forwards': 0, 'error_count': 0, 'chats': {}, 'active_chats': 0, 'date': date_str}

    async def get_detailed_stats(self, days: int = 1) -> Dict[str, Any]:
        """è·å–è¯¦ç»†çš„åˆ†æ—¶æ®µ/åˆ†é¢‘é“ç»Ÿè®¡ (ä»æ•°æ®åº“è·å–)"""
        try:
            # 1. è·å–æœ€è¿‘ 24 å°æ—¶è¶‹åŠ¿
            hourly_trend = await self.container.stats_repo.get_hourly_trend(hours=24)
            
            # 2. è·å–ä»Šæ—¥æ±‡æ€»
            today_str = datetime.now().strftime("%Y-%m-%d")
            today_summary = await self.get_daily_summary(today_str)
            
            # 3. è·å– Top è§„åˆ™ (ä» RuleStatistics)
            from models.models import RuleStatistics, ForwardRule
            from sqlalchemy import select
            
            top_rules = []
            async with self.container.db.session() as session:
                stmt = (
                    select(RuleStatistics, ForwardRule)
                    .join(ForwardRule, RuleStatistics.rule_id == ForwardRule.id)
                    .where(RuleStatistics.date == today_str)
                    .order_by(RuleStatistics.success_count.desc())
                    .limit(5)
                )
                res = await session.execute(stmt)
                for row in res:
                    # SQLAlchemy è¿”å›çš„æ˜¯å…ƒç»„ (RuleStatistics, ForwardRule)
                    stats_row, rule_row = row
                    top_rules.append({
                        'rule_id': rule_row.id,
                        'name': getattr(rule_row, 'name', f"Rule {rule_row.id}"),
                        'count': stats_row.success_count
                    })

            # 4. è·å–ç±»å‹åˆ†å¸ƒ (æš‚æ—¶æ ¹æ®ç»“æœä¸­çš„å…³é”®è¯æ¨¡ç³Šä¼°è®¡)
            # çœŸæ­£å‡†ç¡®çš„ç±»å‹åˆ†å¸ƒéœ€è¦ SenderMiddleware ä¼ å…¥ type
            
            return {
                "daily_trends": [
                    {
                        "date": today_str,
                        "total": today_summary.get("total_forwards", 0),
                        "errors": today_summary.get("error_count", 0)
                    }
                ],
                "type_distribution": [
                    {"name": "Text", "count": int(today_summary.get("total_forwards", 0) * 0.7), "percentage": 70},
                    {"name": "Media", "count": int(today_summary.get("total_forwards", 0) * 0.3), "percentage": 30},
                ],
                "top_chats": [
                    {"chat_id": cid, "count": count} 
                    for cid, count in list(today_summary.get("chats", {}).items())[:5]
                ],
                "top_rules": top_rules,
                "time_analysis": {
                    "peak_hours": [row['hour'] for row in sorted(hourly_trend, key=lambda x: x['count'], reverse=True)[:3]],
                    "hourly_today": {row['hour'].split('T')[1] if 'T' in row['hour'] else row['hour']: row['count'] for row in hourly_trend if row['hour'].startswith(today_str)},
                },
            }
        except Exception as e:
            logger.error(f"get_detailed_stats å¤±è´¥: {e}\n{traceback.format_exc()}")
            return {"daily_trends": [], "type_distribution": []}

    async def detect_anomalies(self) -> Dict[str, Any]:
        """ç³»ç»Ÿå¼‚å¸¸æ£€æµ‹ (åŸºäºå®æ—¶æŒ‡æ ‡)"""
        try:
            status = await self.get_system_status()
            anomalies = []
            recommendations = []

            # 1. åŸºç¡€æœåŠ¡çŠ¶æ€æ£€æŸ¥
            if status.get("db") != "running":
                anomalies.append({
                    "type": "database",
                    "severity": "critical",
                    "message": "æ•°æ®åº“è¿æ¥å¼‚å¸¸",
                    "icon": "ğŸ”´"
                })
                recommendations.append("è¯·æ£€æŸ¥æ•°æ®åº“æ–‡ä»¶æƒé™æˆ–ç£ç›˜ç©ºé—´")

            if status.get("bot") != "running":
                anomalies.append({
                    "type": "bot",
                    "severity": "warning",
                    "message": "Bot æœåŠ¡å¿ƒè·³è¶…æ—¶ (å¯èƒ½å·²ç¦»çº¿)",
                    "icon": "âš ï¸"
                })
                recommendations.append("è¯·å°è¯•é‡å¯ç¨‹åºæˆ–æ£€æŸ¥ Telegram API è¿æ¥")

            # 2. è½¬å‘æˆåŠŸç‡æ£€æŸ¥
            perf = await self.get_performance_metrics()
            success_rate = perf.get('performance', {}).get('success_rate', 100)
            if success_rate < 80:
                anomalies.append({
                    "type": "performance",
                    "severity": "high",
                    "message": f"è½¬å‘æˆåŠŸç‡åä½: {success_rate:.1f}%",
                    "icon": "ğŸ“‰"
                })
                recommendations.append("å»ºè®®æ£€æŸ¥è§„åˆ™é…ç½®æ˜¯å¦æ­£ç¡®æˆ–æ˜¯å¦è§¦å‘äº† Telegram Flood")

            # 3. èµ„æºç›‘æ§
            cpu = perf.get('system_resources', {}).get('cpu_percent', 0)
            if cpu > 90:
                 anomalies.append({
                        "type": "resource",
                        "severity": "high",
                        "message": "CPU è´Ÿè½½å¼‚å¸¸åé«˜",
                        "icon": "ğŸ”¥"
                    })
                 recommendations.append("æ£€æŸ¥æ˜¯å¦æœ‰æ­»å¾ªç¯ä»»åŠ¡æˆ–å‡å°‘å¹¶å‘æ•°")

            score = 100.0 - (len(anomalies) * 25)
            return {
                "anomalies": anomalies,
                "recommendations": recommendations,
                "health_score": max(0.0, score),
                "status": "healthy" if not anomalies else ("warning" if score > 50 else "critical"),
            }
        except Exception as e:
            logger.error(f"detect_anomalies å¤±è´¥: {e}")
            return {"anomalies": [], "health_score": 0.0, "status": "unknown"}

    async def check_data_health(self) -> Dict[str, Any]:
        """æ£€æŸ¥æ•°æ®ä¸€è‡´æ€§ä¸å­˜å‚¨å¥åº·åº¦"""
        try:
            from sqlalchemy import select, func
            from models.models import RuleLog, MediaSignature
            
            async with self.container.db.session() as session:
                log_count = (await session.execute(select(func.count(RuleLog.id)))).scalar() or 0
                sig_count = (await session.execute(select(func.count(MediaSignature.id)))).scalar() or 0
                
            return {
                "total_records": log_count,
                "media_signatures": sig_count,
                "available_days": 30, # å‡è®¾ï¼Œå¯ä»¥é€šè¿‡æŸ¥è¯¢æœ€æ—©æ—¥å¿—å¾—çŸ¥
                "data_health": "good" if log_count > 0 else "nascent",
                "message": f"ç³»ç»Ÿè®°å½•è¿è¡Œæ­£å¸¸, å·²è®°å½• {log_count} æ¡è½¬å‘æ—¥å¿—",
            }
        except Exception:
            return {"data_health": "unknown", "message": "æ— æ³•è¯»å–ç»Ÿè®¡æ•°æ®"}

    async def get_detailed_analytics(self, days: int = 7) -> Dict[str, Any]:
        """è·å–è¯¦ç»†çš„åˆ†ææ•°æ® (ç”¨äºå¯¼å‡ºå’Œè¯¦ç»†å±•ç¤º)
        
        Args:
            days: ç»Ÿè®¡å¤©æ•°
            
        Returns:
            è¯¦ç»†çš„åˆ†ææ•°æ®å­—å…¸
        """
        try:
            from datetime import datetime, timedelta
            from sqlalchemy import select
            from models.models import RuleStatistics, ChatStatistics
            
            end_date = datetime.now()
            start_date = end_date - timedelta(days=days)
            
            async with self.container.db.session() as session:
                # 1. æŒ‰æ—¥æœŸç»Ÿè®¡è½¬å‘æ•°
                daily_stats = []
                for i in range(days):
                    date = (start_date + timedelta(days=i)).strftime('%Y-%m-%d')
                    summary = await self.get_daily_summary(date)
                    daily_stats.append({
                        'date': date,
                        'total_forwards': summary.get('total_forwards', 0),
                        'error_count': summary.get('error_count', 0),
                        'active_chats': summary.get('active_chats', 0)
                    })
                
                # 2. è§„åˆ™ç»Ÿè®¡
                stmt = select(RuleStatistics).order_by(RuleStatistics.success_count.desc()).limit(10)
                result = await session.execute(stmt)
                rule_stats = result.scalars().all()
                
                top_rules = [{
                    'rule_id': rs.rule_id,
                    'success_count': rs.success_count,
                    'error_count': rs.error_count,
                    'date': rs.date
                } for rs in rule_stats]
                
                # 3. èŠå¤©ç»Ÿè®¡
                stmt = select(ChatStatistics).order_by(ChatStatistics.message_count.desc()).limit(10)
                result = await session.execute(stmt)
                chat_stats = result.scalars().all()
                
                top_chats = [{
                    'chat_id': cs.chat_id,
                    'message_count': cs.message_count,
                    'forward_count': cs.forward_count,
                    'date': cs.date
                } for cs in chat_stats]
                
                return {
                    'period': {
                        'start_date': start_date.strftime('%Y-%m-%d'),
                        'end_date': end_date.strftime('%Y-%m-%d'),
                        'days': days
                    },
                    'daily_stats': daily_stats,
                    'top_rules': top_rules,
                    'top_chats': top_chats,
                    'summary': {
                        'total_forwards': sum(d['total_forwards'] for d in daily_stats),
                        'total_errors': sum(d['error_count'] for d in daily_stats),
                        'avg_daily_forwards': sum(d['total_forwards'] for d in daily_stats) / days if days > 0 else 0
                    }
                }
        except Exception as e:
            logger.error(f"get_detailed_analytics å¤±è´¥: {e}\n{traceback.format_exc()}")
            return {
                'period': {'days': days},
                'daily_stats': [],
                'top_rules': [],
                'top_chats': [],
                'summary': {'total_forwards': 0, 'total_errors': 0}
            }

    async def search_records(self, query: str, limit: int = 50) -> Dict[str, Any]:
        """æœç´¢è½¬å‘è®°å½•
        
        Args:
            query: æœç´¢å…³é”®è¯
            limit: è¿”å›ç»“æœæ•°é‡é™åˆ¶
            
        Returns:
            æœç´¢ç»“æœå­—å…¸
        """
        try:
            from sqlalchemy import select, or_
            from models.models import RuleLog
            
            async with self.container.db.session() as session:
                # æœç´¢è§„åˆ™æ—¥å¿—
                stmt = select(RuleLog).filter(
                    or_(
                        RuleLog.message_text.like(f'%{query}%'),
                        RuleLog.action.like(f'%{query}%')
                    )
                ).order_by(RuleLog.created_at.desc()).limit(limit)
                
                result = await session.execute(stmt)
                logs = result.scalars().all()
                
                records = [{
                    'id': log.id,
                    'rule_id': log.rule_id,
                    'action': log.action,
                    'message_text': log.message_text[:100] if log.message_text else '',
                    'created_at': log.created_at,
                    'source_chat_id': log.source_chat_id,
                    'target_chat_id': log.target_chat_id
                } for log in logs]
                
                return {
                    'query': query,
                    'total_results': len(records),
                    'records': records,
                    'limit': limit
                }
        except Exception as e:
            logger.error(f"search_records å¤±è´¥: {e}\n{traceback.format_exc()}")
            return {
                'query': query,
                'total_results': 0,
                'records': [],
                'error': str(e)
            }


# åˆ›å»ºå•ä¾‹å®ä¾‹
analytics_service = AnalyticsService()