import logging
import traceback
import os
from pathlib import Path
from datetime import datetime, timedelta, timezone
from typing import Dict, Any

from services.network.bot_heartbeat import get_heartbeat
from services.dedup.engine import smart_deduplicator
from core.helpers.realtime_stats import realtime_stats_cache

logger = logging.getLogger(__name__)

class AnalyticsService:
    """
    æ•°æ®åˆ†ææœåŠ¡
    è´Ÿè´£èšåˆæ¥è‡ªå„ä¸ª Repository å’Œå·¥å…·ç±»çš„ç»Ÿè®¡ä¿¡æ¯
    """
    
    def __init__(self, container=None):
        self._container = container

    @property
    def container(self):
        if self._container:
            return self._container
        from core.container import container
        return container

    def _get_dir_size(self, path: Path) -> int:
        """é€’å½’è·å–ç›®å½•å¤§å° (Bytes)"""
        total = 0
        try:
            if not path.exists():
                return 0
            for entry in os.scandir(path):
                if entry.is_file():
                    total += entry.stat().st_size
                elif entry.is_dir():
                    total += self._get_dir_size(Path(entry.path))
        except Exception as e:
            logger.debug(f"è®¡ç®—ç›®å½•å¤§å°æ—¶è·³è¿‡ {path}: {e}")
        return total

    async def get_data_size_mb(self) -> float:
        """è·å–æ•°æ®ç›®å½•æ€»å¤§å° (MB)"""
        try:
            from core.config import settings
            # ç»Ÿä¸€ä½¿ç”¨ DATA_ROOT
            data_root = Path(settings.DATA_ROOT)
            total_bytes = self._get_dir_size(data_root)
            return round(total_bytes / (1024 * 1024), 2)
        except Exception as e:
            logger.error(f"è·å–æ•°æ®ç›®å½•å¤§å°å¤±è´¥: {e}")
            return 0.0

    async def get_analytics_overview(self) -> Dict[str, Any]:
        """è·å–ç³»ç»Ÿç»Ÿè®¡æ€»è§ˆ"""
        try:
            # 1. è·å–è§„åˆ™ç»Ÿè®¡
            rule_stats = await self.container.task_repo.get_rule_stats()
            overview = {
                'total_rules': rule_stats.get('total_rules', 0),
                'active_rules': rule_stats.get('active_rules', 0),
                'total_chats': rule_stats.get('total_chats', 0)
            }
            
            # 2. è·å–è½¬å‘ç»Ÿè®¡ (ä»ç¼“å­˜è·å–ä»¥å¯¹é½ Bot èœå•)
            forward_stats = {'total_forwards': 0}
            try:
                from core.helpers.realtime_stats import realtime_stats_cache
                fs = await realtime_stats_cache.get_forward_stats()
                if isinstance(fs, dict):
                    ft = int(((fs.get('today') or {}).get('total_forwards') or 0))
                    if ft >= 0:
                        forward_stats = {'total_forwards': ft}
            except Exception as e:
                logger.warning(f"AnalyticsService è·å–è½¬å‘ç»Ÿè®¡å¤±è´¥: {e}")
            
            # 3. è·å–å»é‡ç»Ÿè®¡
            dedup_stats = {'cached_signatures': 0}
            try:
                dedup = smart_deduplicator.get_stats()
                dedup_stats = {'cached_signatures': int(dedup.get('cached_signatures', 0))}
            except Exception as e:
                logger.error(f"AnalyticsService è·å–å»é‡ç»Ÿè®¡å¤±è´¥: {e}")
                
            # 4. è·å– HLL ç‹¬ç«‹æ¶ˆæ¯ä¼°è®¡
            hll_stats = {'unique_messages_estimate': 0}
            try:
                from core.algorithms.hll import GlobalHLL
                hll = GlobalHLL.get_hll("unique_messages_today")
                hll_stats = {'unique_messages_estimate': hll.count()}
            except Exception as e:
                logger.warning(f"AnalyticsService è·å– HLL ç»Ÿè®¡å¤±è´¥: {e}")

            # 5. ç»„åˆæœ€ç»ˆæ•°æ®ä»¥å¯¹é½ Renderer éœ€æ±‚
            # è·å–æ´»è·ƒåˆ†ææ•°æ®(å¯èƒ½éœ€è¦ä» get_detailed_stats ç»„åˆéƒ¨åˆ†)
            detailed = await self.get_detailed_stats(days=1)
            
            # è·å–æ˜¨æ—¥ç»Ÿè®¡
            yesterday_str = (datetime.now() - timedelta(days=1)).strftime("%Y-%m-%d")
            yesterday_summary = await self.get_daily_summary(yesterday_str)
            yesterday_total = yesterday_summary.get('total_forwards', 0)
            
            # å¼ºåŒ– overview å­—æ®µä»¥å¯¹é½ main_menu_renderer.py:140
            system_status = await self.get_system_status()
            enriched_overview = {
                'total_rules': overview.get('total_rules', 0),
                'active_rules': overview.get('active_rules', 0),
                'total_chats': overview.get('total_chats', 0),
                'today_total': forward_stats.get('total_forwards', 0),
                'yesterday_total': yesterday_total,
                'data_size_mb': system_status.get('system_resources', {}).get('total_size_mb', 0.0),
                'trend': {
                    'text': 'ğŸ“ˆ ç¨³æ­¥å¢é•¿' if forward_stats.get('total_forwards', 0) > yesterday_total else 'â¸ï¸ å¾…æœºä¸­',
                    'percentage': round((forward_stats.get('total_forwards', 0) - yesterday_total) / yesterday_total * 100, 1) if yesterday_total > 0 else 0
                },
                'hourly': [{'hour': k, 'count': v} for k, v in detailed.get('time_analysis', {}).get('hourly_today', {}).items()]
            }

            return {
                'overview': enriched_overview,
                'forward_stats': forward_stats,
                'dedup_stats': dedup_stats,
                'hll_stats': hll_stats,
                'top_type': next(iter(detailed.get('type_distribution', [])), None),
                'top_chat': next(iter(detailed.get('top_chats', [])), None),
                'top_rule': next(iter(detailed.get('top_rules', [])), None)
            }
        except Exception as e:
            logger.error(f"get_analytics_overview å¤±è´¥: {e}\n{traceback.format_exc()}")
            return {
                'overview': {'total_rules': 0, 'active_rules': 0, 'total_chats': 0},
                'forward_stats': {'total_forwards': 0},
                'dedup_stats': {'cached_signatures': 0},
                'error': str(e)
            }

    async def get_system_status(self) -> Dict[str, Any]:
        """è·å–å„é¡¹æœåŠ¡è¿è¡ŒçŠ¶æ€ (ä¸ºç³»ç»Ÿä¸­å¿ƒé¡µé¢æä¾›çœŸå®æ•°æ®)"""
        try:
            # 1. åŸºç¡€èµ„æºçŠ¶æ€ (CPU/MEM/Uptime)
            import psutil
            import time
            from datetime import datetime
            
            # è¿è¡Œæ—¶é—´
            boot_time = datetime.fromtimestamp(psutil.boot_time())
            uptime_hours = (datetime.now() - boot_time).total_seconds() / 3600
            
            # æ•°æ®å¤§å°
            total_size_mb = await self.get_data_size_mb()
            
            system_resources = {
                "cpu_percent": psutil.cpu_percent(interval=0.1),
                "memory_percent": psutil.virtual_memory().percent,
                "uptime_hours": round(uptime_hours, 1),
                "total_size_mb": total_size_mb,
                "status": "healthy" if psutil.cpu_percent() < 80 else "warning"
            }

            # 2. é…ç½®ä¸è¿è¡ŒçŠ¶æ€
            db_status = "running"
            from core.container import container
            try:
                async with container.db.get_session() as session:
                    from sqlalchemy import select, func
                    from models.models import ForwardRule, RuleLog
                    
                    # è½¬å‘è§„åˆ™ç»Ÿè®¡
                    total_rules = (await session.execute(select(func.count(ForwardRule.id)))).scalar() or 0
                    active_rules = (await session.execute(select(func.count(ForwardRule.id)).where(ForwardRule.enable_rule == True))).scalar() or 0
                    forward_rules_status = f"{active_rules}/{total_rules} å¯ç”¨"
                    
                    # æ•°æ®è®°å½•çŠ¶æ€ (æ£€æŸ¥æœ€è¿‘æ˜¯å¦æœ‰æ—¥å¿—æ¡ç›®)
                    recent_logs = (await session.execute(select(func.count(RuleLog.id)).limit(1))).scalar() or 0
                    data_recording_status = "âœ… è¿è¡Œä¸­" if recent_logs > 0 else "ğŸ’¤ å¾…æœº"
            except Exception as e:
                logger.error(f"AnalyticsService æ•°æ®åº“æ£€æŸ¥å¤±è´¥: {e}")
                db_status = "unhealthy"
                forward_rules_status = "æœªçŸ¥"
                data_recording_status = "æœªçŸ¥"

            # 3. æ™ºèƒ½å»é‡çŠ¶æ€
            dedup_conf = smart_deduplicator.config or {}
            dedup_enabled = dedup_conf.get('enable_time_window') or dedup_conf.get('enable_content_hash')
            smart_dedup_status = "âœ… å·²å¼€å¯" if dedup_enabled else "âŒ å·²å…³é—­"

            # 4. Bot/User Client çŠ¶æ€
            bot_connected = False
            user_connected = False
            try:
                if self.container.bot_client:
                    bot_connected = self.container.bot_client.is_connected()
                if self.container.user_client:
                    user_connected = self.container.user_client.is_connected()
            except Exception as e:
                logger.warning(f"è·å– Client è¿æ¥çŠ¶æ€å¤±è´¥: {e}")

            # 5. ç»„è£…è¿”å›æ•°æ® (å¯¹é½ MainMenuRenderer.render_system_hub)
            return {
                "system_resources": system_resources,
                "config_status": {
                    "forward_rules": forward_rules_status,
                    "smart_dedup": smart_dedup_status,
                    "data_recording": data_recording_status
                },
                "overall_status": "healthy" if system_resources["status"] == "healthy" and db_status == "running" else "warning",
                "db": db_status, 
                "bot": "running" if bot_connected else "stopped",
                "user": "running" if user_connected else "stopped",
                "dedup": "running" if dedup_enabled else "stopped"
            }
        except Exception as e:
            logger.error(f"get_system_status å¤±è´¥: {e}")
            return {
                "system_resources": {"cpu_percent": 0, "memory_percent": 0, "status": "unknown"},
                "config_status": {
                    "forward_rules": "æœªçŸ¥",
                    "smart_dedup": "æœªçŸ¥",
                    "data_recording": "æœªçŸ¥"
                },
                "overall_status": "unknown"
            }

    async def get_performance_metrics(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½æŒ‡æ ‡å’Œèµ„æºå ç”¨ (çœŸå®æ•°æ®åº“ç»Ÿè®¡)"""
        try:
            # 1. è·å–ç³»ç»Ÿèµ„æºç»Ÿè®¡
            system_stats = await realtime_stats_cache.get_system_stats(force_refresh=True)
            system_resources = system_stats.get("system_resources", {})

            # 2. è·å–è½¬å‘ç»Ÿè®¡ä»¥è®¡ç®—æˆåŠŸç‡
            forward_stats = await realtime_stats_cache.get_forward_stats()
            today_stats = forward_stats.get("today", {})
            success_rate = 100.0
            if today_stats.get("total_forwards", 0) > 0:
                errors = today_stats.get("error_count", 0)
                success_rate = ((today_stats["total_forwards"] - errors) / today_stats["total_forwards"]) * 100

            # 3. è®¡ç®—å®æ—¶ TPS å’Œ å¹³å‡å“åº”æ—¶é—´ (åŸºäºæœ€è¿‘ 10 åˆ†é’Ÿ)
            current_tps = 0.0
            avg_response_time = 0.0
            try:
                from sqlalchemy import select, func
                from models.models import RuleLog
                from datetime import datetime, timedelta
                
                cutoff = datetime.utcnow() - timedelta(minutes=10)
                async with self.container.db.get_session() as session:
                    perf_stmt = select(
                        func.count(RuleLog.id).label('count'),
                        func.avg(RuleLog.processing_time).label('avg_time')
                    ).where(RuleLog.created_at >= cutoff)
                    
                    res = await session.execute(perf_stmt)
                    row = res.first()
                    if row and row.count:
                        current_tps = round(row.count / 600, 2) # è¿‡å» 10 åˆ†é’Ÿå¹³å‡ TPS
                        avg_response_time = round((row.avg_time or 0) / 1000, 3) # è½¬ä¸ºç§’
            except Exception as e:
                logger.warning(f"è®¡ç®— TPS/è€—æ—¶å¤±è´¥: {e}")

            # 4. è·å–é˜Ÿåˆ—çŠ¶æ€
            active_queues = 0
            pending_tasks = 0
            avg_delay = "0s"
            try:
                queue_status = await self.container.task_repo.get_queue_status()
                active_queues = queue_status.get("active_queues", 0)
                pending_tasks = queue_status.get("pending_tasks", 0)
                avg_delay = queue_status.get("avg_delay", "0s")
            except Exception: pass

            return {
                "system_resources": {
                    "cpu_percent": system_resources.get("cpu_percent", 0),
                    "memory_percent": system_resources.get("memory_percent", 0),
                    "status": "healthy" if system_resources.get("cpu_percent", 0) < 80 else "warning",
                },
                "performance": {
                    "success_rate": success_rate,
                    "avg_response_time": avg_response_time or 0, # é»˜è®¤ä¿åº•å€¼
                    "current_tps": current_tps,
                    "status": "good" if success_rate > 90 else "poor",
                },
                "queue_status": {
                    "active_queues": active_queues,
                    "pending_tasks": pending_tasks,
                    "avg_delay": avg_delay,
                    "error_rate": f"{(100-success_rate):.1f}%",
                },
            }
        except Exception as e:
            logger.error(f"get_performance_metrics å¤±è´¥: {e}")
            return {
                "system_resources": {"cpu_percent": 0, "memory_percent": 0},
                "performance": {"success_rate": 0, "avg_response_time": 0, "current_tps": 0},
                "queue_status": {"active_queues": 0},
            }

    async def get_daily_summary(self, date_str: str) -> Dict[str, Any]:
        """è·å–æŒ‡å®šæ—¥æœŸçš„æ¯æ—¥æ±‡æ€» (ä»æ•°æ®åº“è·å–)"""
        try:
            from sqlalchemy import select, func
            from models.models import RuleLog, ChatStatistics

            async with self.container.db.get_session() as session:
                # 1. ç»Ÿè®¡æ€»è½¬å‘æ•°å’Œé”™è¯¯æ•° (ä» RuleLog)
                stats_stmt = (
                    select(
                        func.count(RuleLog.id).label('total'),
                        func.sum(RuleLog.action == 'error').label('errors')
                    )
                    .where(func.strftime('%Y-%m-%d', RuleLog.created_at) == date_str)
                )
                stats_res = await session.execute(stats_stmt)
                row = stats_res.first()
                total = row.total if row and row.total else 0
                errors = row.errors if row and row.errors else 0

                # 2. ç»Ÿè®¡æ´»è·ƒèŠå¤© (ä» ChatStatistics)
                chats_stmt = (
                    select(ChatStatistics)
                    .where(ChatStatistics.date == date_str)
                    .order_by(ChatStatistics.forward_count.desc())
                )
                chats_res = await session.execute(chats_stmt)
                chats_data = chats_res.scalars().all()
                
                chats_dict = {str(c.chat_id): c.forward_count for c in chats_data}
                
                # 3. ç»Ÿè®¡èŠ‚çœæµé‡ (ä» ChatStatistics)
                traffic_stmt = (
                    select(func.sum(ChatStatistics.saved_traffic_bytes))
                    .where(ChatStatistics.date == date_str)
                )
                saved_bytes = (await session.execute(traffic_stmt)).scalar() or 0
                
                return {
                    'total_forwards': total,
                    'error_count': errors,
                    'chats': chats_dict,
                    'active_chats': len(chats_dict),
                    'date': date_str,
                    'saved_traffic_bytes': saved_bytes
                }
        except Exception as e:
            logger.error(f"get_daily_summary å¤±è´¥ for {date_str}: {e}")
            return {'total_forwards': 0, 'error_count': 0, 'chats': {}, 'active_chats': 0, 'date': date_str}

    async def get_detailed_stats(self, days: int = 1) -> Dict[str, Any]:
        """è·å–è¯¦ç»†çš„åˆ†æ—¶æ®µ/åˆ†é¢‘é“ç»Ÿè®¡ (ä»æ•°æ®åº“è·å–)"""
        try:
            # 1. è·å–æœ€è¿‘ 24 å°æ—¶è¶‹åŠ¿
            hourly_trend = await self.container.stats_repo.get_hourly_trend(hours=24)
            
            # 2. è·å–ä»Šæ—¥æ±‡æ€»
            today_str = datetime.now().strftime("%Y-%m-%d")
            today_summary = await self.get_daily_summary(today_str)
            
            # 3. è·å– Top è§„åˆ™ (ä» RuleStatistics)
            from models.models import RuleStatistics, ForwardRule
            from sqlalchemy import select
            
            top_rules = []
            async with self.container.db.get_session() as session:
                stmt = (
                    select(RuleStatistics, ForwardRule)
                    .join(ForwardRule, RuleStatistics.rule_id == ForwardRule.id)
                    .where(RuleStatistics.date == today_str)
                    .order_by(RuleStatistics.success_count.desc())
                    .limit(5)
                )
                res = await session.execute(stmt)
                for row in res:
                    # SQLAlchemy è¿”å›çš„æ˜¯å…ƒç»„ (RuleStatistics, ForwardRule)
                    stats_row, rule_row = row
                    top_rules.append({
                        'rule_id': rule_row.id,
                        'name': getattr(rule_row, 'name', f"Rule {rule_row.id}"),
                        'count': stats_row.success_count
                    })

            # 4. è·å–ç±»å‹åˆ†å¸ƒ (ä» RuleLog çœŸå®èšåˆ)
            type_dist = []
            try:
                from sqlalchemy import select, func
                from models.models import RuleLog
                async with self.container.db.get_session() as session:
                    type_stmt = select(
                        RuleLog.message_type,
                        func.count(RuleLog.id).label('count')
                    ).where(
                        func.strftime('%Y-%m-%d', RuleLog.created_at) == today_str
                    ).group_by(RuleLog.message_type)
                    
                    type_res = await session.execute(type_stmt)
                    total_count = 0
                    temp_dist = []
                    for row in type_res:
                        # ä¿®å¤: ç¡®ä¿ None/Unknown æ˜ å°„ä¸º "Text" (å¸¸è§æƒ…å†µ)
                        m_type = row.message_type
                        if not m_type or m_type.lower() == 'unknown':
                            m_type = "Text"
                        else:
                            m_type = m_type.capitalize()
                            
                        count = row.count or 0
                        total_count += count
                        
                        # åˆå¹¶åŒåç±»å‹ (å¦‚ 'text' å’Œ 'Text')
                        found = False
                        for item in temp_dist:
                            if item["name"] == m_type:
                                item["count"] += count
                                found = True
                                break
                        if not found:
                            temp_dist.append({"name": m_type, "count": count})
                    
                    if total_count > 0:
                        for item in temp_dist:
                            item["percentage"] = round((item["count"] / total_count) * 100, 1)
                            type_dist.append(item)
            except Exception as e:
                logger.warning(f"è·å–ç±»å‹åˆ†å¸ƒå¤±è´¥: {e}")
            
            if not type_dist:
                 # å›é€€æ–¹æ¡ˆ - æ—¢ç„¶ç”¨æˆ·é€šè¿‡çœŸå®æ•°æ®åé¦ˆï¼Œåˆ™ä¸å†ç”Ÿæˆè™šå‡åˆ†å¸ƒ
                 pass
            
            return {
                "daily_trends": [
                    {
                        "date": today_str,
                        "total": today_summary.get("total_forwards", 0),
                        "errors": today_summary.get("error_count", 0)
                    }
                ],
                "type_distribution": type_dist,
                "top_chats": [
                    {"chat_id": cid, "name": await self._resolve_chat_name(cid), "count": count} 
                    for cid, count in list(today_summary.get("chats", {}).items())[:5]
                ],
                "top_rules": top_rules,
                "time_analysis": {
                    "peak_hours": [row['hour'] for row in sorted(hourly_trend, key=lambda x: x['count'], reverse=True)[:3]],
                    "hourly_today": {row['hour'].split('T')[1] if 'T' in row['hour'] else row['hour']: row['count'] for row in hourly_trend if row['hour'].startswith(today_str)},
                },
            }
        except Exception as e:
            logger.error(f"get_detailed_stats å¤±è´¥: {e}\n{traceback.format_exc()}")
            return {"daily_trends": [], "type_distribution": [], "top_chats": [], "top_rules": []}

    async def _resolve_chat_name(self, chat_id: Any) -> str:
        """è§£æèŠå¤©åç§°"""
        try:
            # å°è¯•ä»æ•°æ®åº“è·å–
            from models.models import Chat
            from sqlalchemy import select
            async with self.container.db.get_session() as session:
                stmt = select(Chat).where(Chat.telegram_chat_id == str(chat_id))
                res = await session.execute(stmt)
                chat = res.scalar_one_or_none()
                if chat and chat.name:
                    return chat.name
            
            # å°è¯•ä» chat_info_service è·å–
            name = await self.container.chat_info_service.get_chat_name(int(chat_id))
            if name:
                return name
        except Exception:
            pass
        return str(chat_id)[:12]

    async def detect_anomalies(self) -> Dict[str, Any]:
        """ç³»ç»Ÿå¼‚å¸¸æ£€æµ‹ (åŸºäºå®æ—¶æŒ‡æ ‡)"""
        try:
            status = await self.get_system_status()
            anomalies = []
            recommendations = []

            # 1. åŸºç¡€æœåŠ¡çŠ¶æ€æ£€æŸ¥
            if status.get("db") != "running":
                anomalies.append({
                    "type": "database",
                    "severity": "critical",
                    "message": "æ•°æ®åº“è¿æ¥å¼‚å¸¸",
                    "icon": "ğŸ”´"
                })
                recommendations.append("è¯·æ£€æŸ¥æ•°æ®åº“æ–‡ä»¶æƒé™æˆ–ç£ç›˜ç©ºé—´")

            if status.get("bot") != "running":
                anomalies.append({
                    "type": "bot",
                    "severity": "warning",
                    "message": "Bot æœåŠ¡å¿ƒè·³è¶…æ—¶ (å¯èƒ½å·²ç¦»çº¿)",
                    "icon": "âš ï¸"
                })
                recommendations.append("è¯·å°è¯•é‡å¯ç¨‹åºæˆ–æ£€æŸ¥ Telegram API è¿æ¥")

            # 2. è½¬å‘æˆåŠŸç‡æ£€æŸ¥
            perf = await self.get_performance_metrics()
            success_rate = perf.get('performance', {}).get('success_rate', 100)
            if success_rate < 80:
                anomalies.append({
                    "type": "performance",
                    "severity": "high",
                    "message": f"è½¬å‘æˆåŠŸç‡åä½: {success_rate:.1f}%",
                    "icon": "ğŸ“‰"
                })
                recommendations.append("å»ºè®®æ£€æŸ¥è§„åˆ™é…ç½®æ˜¯å¦æ­£ç¡®æˆ–æ˜¯å¦è§¦å‘äº† Telegram Flood")

            # 3. èµ„æºç›‘æ§
            cpu = perf.get('system_resources', {}).get('cpu_percent', 0)
            if cpu > 90:
                 anomalies.append({
                        "type": "resource",
                        "severity": "high",
                        "message": "CPU è´Ÿè½½å¼‚å¸¸åé«˜",
                        "icon": "ğŸ”¥"
                    })
                 recommendations.append("æ£€æŸ¥æ˜¯å¦æœ‰æ­»å¾ªç¯ä»»åŠ¡æˆ–å‡å°‘å¹¶å‘æ•°")

            score = 100.0 - (len(anomalies) * 25)
            return {
                "anomalies": anomalies,
                "recommendations": recommendations,
                "health_score": max(0.0, score),
                "status": "healthy" if not anomalies else ("warning" if score > 50 else "critical"),
            }
        except Exception as e:
            logger.error(f"detect_anomalies å¤±è´¥: {e}")
            return {"anomalies": [], "health_score": 0.0, "status": "unknown"}

    async def check_data_health(self) -> Dict[str, Any]:
        """æ£€æŸ¥æ•°æ®ä¸€è‡´æ€§ä¸å­˜å‚¨å¥åº·åº¦"""
        try:
            from sqlalchemy import select, func
            from models.models import RuleLog, MediaSignature
            
            async with self.container.db.get_session() as session:
                log_count = (await session.execute(select(func.count(RuleLog.id)))).scalar() or 0
                sig_count = (await session.execute(select(func.count(MediaSignature.id)))).scalar() or 0
                
            return {
                "total_records": log_count,
                "media_signatures": sig_count,
                "available_days": 30, # å‡è®¾ï¼Œå¯ä»¥é€šè¿‡æŸ¥è¯¢æœ€æ—©æ—¥å¿—å¾—çŸ¥
                "data_health": "good" if log_count > 0 else "nascent",
                "message": f"ç³»ç»Ÿè®°å½•è¿è¡Œæ­£å¸¸, å·²è®°å½• {log_count} æ¡è½¬å‘æ—¥å¿—",
            }
        except Exception:
            return {"data_health": "unknown", "message": "æ— æ³•è¯»å–ç»Ÿè®¡æ•°æ®"}

    async def get_detailed_analytics(self, days: int = 7) -> Dict[str, Any]:
        """è·å–è¯¦ç»†çš„åˆ†ææ•°æ® (ç”¨äºå¯¼å‡ºå’Œè¯¦ç»†å±•ç¤º)
        
        Args:
            days: ç»Ÿè®¡å¤©æ•°
            
        Returns:
            è¯¦ç»†çš„åˆ†ææ•°æ®å­—å…¸
        """
        try:
            from datetime import datetime, timedelta
            from sqlalchemy import select
            from models.models import RuleStatistics, ChatStatistics
            
            end_date = datetime.now()
            start_date = end_date - timedelta(days=days)
            
            async with self.container.db.get_session() as session:
                # 1. æŒ‰æ—¥æœŸç»Ÿè®¡è½¬å‘æ•°
                daily_stats = []
                for i in range(days):
                    date = (start_date + timedelta(days=i)).strftime('%Y-%m-%d')
                    summary = await self.get_daily_summary(date)
                    daily_stats.append({
                        'date': date,
                        'total_forwards': summary.get('total_forwards', 0),
                        'error_count': summary.get('error_count', 0),
                        'active_chats': summary.get('active_chats', 0)
                    })
                
                # 2. è§„åˆ™ç»Ÿè®¡
                stmt = select(RuleStatistics).order_by(RuleStatistics.success_count.desc()).limit(10)
                result = await session.execute(stmt)
                rule_stats = result.scalars().all()
                
                top_rules = [{
                    'rule_id': rs.rule_id,
                    'success_count': rs.success_count,
                    'error_count': rs.error_count,
                    'date': rs.date
                } for rs in rule_stats]
                
                # 3. èŠå¤©ç»Ÿè®¡
                stmt = select(ChatStatistics).order_by(ChatStatistics.message_count.desc()).limit(10)
                result = await session.execute(stmt)
                chat_stats = result.scalars().all()
                
                top_chats = [{
                    'chat_id': cs.chat_id,
                    'message_count': cs.message_count,
                    'forward_count': cs.forward_count,
                    'date': cs.date
                } for cs in chat_stats]
                
                return {
                    'period': {
                        'start_date': start_date.strftime('%Y-%m-%d'),
                        'end_date': end_date.strftime('%Y-%m-%d'),
                        'days': days
                    },
                    'daily_stats': daily_stats,
                    'top_rules': top_rules,
                    'top_chats': top_chats,
                    'summary': {
                        'total_forwards': sum(d['total_forwards'] for d in daily_stats),
                        'total_errors': sum(d['error_count'] for d in daily_stats),
                        'avg_daily_forwards': sum(d['total_forwards'] for d in daily_stats) / days if days > 0 else 0
                    }
                }
        except Exception as e:
            logger.error(f"get_detailed_analytics å¤±è´¥: {e}\n{traceback.format_exc()}")
            return {
                'period': {'days': days},
                'daily_stats': [],
                'top_rules': [],
                'top_chats': [],
                'summary': {'total_forwards': 0, 'total_errors': 0}
            }

    async def search_records(self, query: str, limit: int = 50) -> Dict[str, Any]:
        """æœç´¢è½¬å‘è®°å½•
        
        Args:
            query: æœç´¢å…³é”®è¯
            limit: è¿”å›ç»“æœæ•°é‡é™åˆ¶
            
        Returns:
            æœç´¢ç»“æœå­—å…¸
        """
        try:
            from sqlalchemy import select, or_
            from models.models import RuleLog, ForwardRule
            
            from sqlalchemy.orm import joinedload
            async with self.container.db.get_session() as session:
                # æœç´¢è§„åˆ™æ—¥å¿—ï¼Œé¢„åŠ è½½å…³è”çš„è§„åˆ™ä»¥åŠè§„åˆ™å…³è”çš„èŠå¤©å®ä½“ï¼Œç¡®ä¿æ˜¾ç¤ºåç§°è€Œé "æœªçŸ¥"
                stmt = select(RuleLog).options(
                    joinedload(RuleLog.rule).joinedload(ForwardRule.source_chat),
                    joinedload(RuleLog.rule).joinedload(ForwardRule.target_chat)
                ).filter(
                    or_(
                        RuleLog.message_text.like(f'%{query}%'),
                        RuleLog.action.like(f'%{query}%')
                    )
                ).order_by(RuleLog.created_at.desc()).limit(limit)
                
                result = await session.execute(stmt)
                logs = result.scalars().all()
                
                records = []
                for log in logs:
                    source_title = "æœªçŸ¥"
                    target_title = "æœªçŸ¥"
                    
                    if log.rule:
                        if log.rule.source_chat:
                            c = log.rule.source_chat
                            source_title = c.title or c.name or c.username or str(c.telegram_chat_id)
                        else:
                            source_title = str(log.rule.source_chat_id)
                            
                        if log.rule.target_chat:
                            c = log.rule.target_chat
                            target_title = c.title or c.name or c.username or str(c.telegram_chat_id)
                        else:
                            target_title = str(log.rule.target_chat_id)
                    
                    records.append({
                        'id': log.id,
                        'rule_id': log.rule_id,
                        'action': log.action,
                        'message_text': log.message_text[:100] if log.message_text else '',
                        'created_at': log.created_at.replace(tzinfo=timezone.utc).isoformat() if hasattr(log.created_at, 'isoformat') else str(log.created_at),
                        'source_chat_id': source_title, # ä¿ç•™æ—§å­—æ®µä½†å¡«å…¥åç§°ä»¥ä¿®å¤æ˜¾ç¤º
                        'target_chat_id': target_title,
                        'source_chat': source_title,    # æ–°å¢å¯¹é½ RuleDTOMapper
                        'target_chat': target_title,
                        'source_title': source_title,   # å†—ä½™å­—æ®µæé«˜å…¼å®¹æ€§
                        'target_title': target_title
                    })
                
                return {
                    'query': query,
                    'total_results': len(records),
                    'records': records,
                    'limit': limit
                }
        except Exception as e:
            logger.error(f"search_records å¤±è´¥: {e}\n{traceback.format_exc()}")
            return {
                'query': query,
                'total_results': 0,
                'records': [],
                'error': str(e)
            }


# åˆ›å»ºå•ä¾‹å®ä¾‹
analytics_service = AnalyticsService()