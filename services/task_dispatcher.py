import asyncio
import json
import time
from datetime import datetime
from core.config import settings
from core.logging import get_logger

logger = get_logger(__name__)

class TaskDispatcher:
    """
    ä¸­å¤®ä»»åŠ¡åˆ†å‘å™¨ (Centralized Task Dispatcher)
    å€Ÿé‰´æˆç†Ÿæ¶ˆæ¯é˜Ÿåˆ— (Celery/SQS) çš„ Prefetch ä¸ Backpressure è®¾è®¡ã€‚
    è´Ÿè´£ä»æ•°æ®åº“æ‰¹é‡æ‹‰å–ä»»åŠ¡ï¼Œé€šè¿‡ pre-parse å‡è½» Worker è´Ÿè½½ï¼Œå¹¶æä¾›åŸå­é”å®šã€‚
    """
    def __init__(self, repo, queue: asyncio.Queue, client=None):
        self.repo = repo
        self.queue = queue
        self.client = client
        self.running = False
        self._task = None
        
        # [NEW] å®ä½“é¢„çƒ­ç¼“å­˜ (é˜²æ­¢é‡å¤è°ƒç”¨ API)
        self._entity_cache = set()
        self._last_cache_clear = time.time()
        
        # è‡ªåˆ¶ä¼‘çœ é…ç½® (Inspired by Binary Exponential Backoff)
        self.min_sleep = getattr(settings, 'TASK_DISPATCHER_SLEEP_BASE', 1.0)
        self.max_sleep = getattr(settings, 'TASK_DISPATCHER_MAX_SLEEP', 30.0)
        self.current_sleep = self.min_sleep
        
        # ç»Ÿè®¡æŒ‡æ ‡ (Observability)
        self.total_dispatched = 0
        self.last_fetch_count = 0
        self.start_time = None

    async def start(self):
        """å¯åŠ¨åˆ†å‘å¾ªç¯"""
        if self.running:
            return
        self.running = True
        self.start_time = time.time()
        self._task = asyncio.create_task(self._dispatch_loop(), name="task_dispatcher")
        logger.info(f"ğŸš€ TaskDispatcher å¯åŠ¨ (Batch: {settings.TASK_DISPATCHER_BATCH_SIZE}, QueueSize: {settings.WORKER_QUEUE_SIZE})")

    async def stop(self):
        """åœæ­¢åˆ†å‘å¾ªç¯"""
        self.running = False
        if self._task:
            self._task.cancel()
            try:
                await self._task
            except asyncio.CancelledError:
                pass
        logger.info("ğŸ›‘ TaskDispatcher å·²åœæ­¢")

    async def _dispatch_loop(self):
        """ä¸»åˆ†å‘æ ¸å¿ƒå¾ªç¯ (Central Fetch & Pre-Parse)"""
        while self.running:
            try:
                # 1. èƒŒå‹æ§åˆ¶ (Backpressure)
                if self.queue.full():
                    logger.debug("Dispatcher è§¦å‘èƒŒå‹åœé¡¿ (Queue Full)")
                    await asyncio.sleep(1.0)
                    continue

                # 2. æ‰¹é‡æ‹‰å–ä¸åŸå­é”å®š
                batch_size = settings.TASK_DISPATCHER_BATCH_SIZE
                tasks = await self.repo.fetch_next(limit=batch_size)
                
                if not tasks:
                    self.last_fetch_count = 0
                    await self._adaptive_sleep()
                    continue

                # [NEW] é¢„çƒ­å®ä½“ç¼“å­˜ (Entity Prefetching)
                if self.client:
                    await self._prefetch_entities(tasks)

                # 3. é¢„å¤„ç†ä¸åˆ†å‘
                self._reset_sleep()
                
                # [Optimization] åª’ä½“ç»„èšåˆé€»è¾‘
                # ç¡®ä¿åŒä¸€åª’ä½“ç»„çš„ä»»åŠ¡ä½œä¸ºä¸€ä¸ªæ‰¹æ¬¡åˆ†å‘ç»™åŒä¸€ä¸ª Worker
                # ä»è€Œå‡å°‘ Worker é‡å¤è·å–åŸå§‹æ¶ˆæ¯å’Œä¸‹è½½åª’ä½“çš„å¼€é”€
                task_groups = {}
                for task in tasks:
                    try:
                        if task.task_data:
                            task.payload = json.loads(task.task_data)
                        else:
                            task.payload = {}
                        
                        # ç¡®å®šåˆ†ç»„ ID (æœ‰ grouped_id åˆ™ä½¿ç”¨ï¼Œå¦åˆ™ä½¿ç”¨ ID æ¨¡æ‹Ÿ)
                        gid = task.grouped_id or f"single-{task.id}"
                        if gid not in task_groups:
                            task_groups[gid] = []
                        task_groups[gid].append(task)
                        
                    except Exception as e:
                        logger.error(f"Task pre-parse failed for ID {task.id}: {e}")
                        task.payload = {}
                        task_groups[f"err-{task.id}"] = [task]

                for gid, group_list in task_groups.items():
                    # å…¥é˜Ÿ (ä½œä¸º List[TaskQueue] è½½è·)
                    await self.queue.put(group_list)
                    self.total_dispatched += len(group_list)
                    self.last_fetch_count = len(tasks)
                
                # [Anti-Starvation] ç¨å¾®å‡ºè®©äº‹ä»¶å¾ªç¯æ—¶é—´
                await asyncio.sleep(0.05)

            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"Dispatcher loop panic: {e}", exc_info=True)
                await asyncio.sleep(5) # ä¸¥é‡é”™è¯¯æ—¶è¿›è¡Œå†·é™æœŸä¼‘çœ 

    async def _adaptive_sleep(self):
        """è‡ªé€‚åº”é€€é¿ (Exponential Backoff with Jitter)"""
        import random
        # å¢åŠ éšæœºæ‰°åŠ¨å› å­ï¼Œé˜²æ­¢å¤šä¸ª Dispatcher å¹¶å‘å¯åŠ¨æ—¶çš„æƒŠç¾¤æ•ˆåº”
        jitter = random.uniform(0.8, 1.2)
        sleep_time = self.current_sleep * jitter
        
        logger.debug(f"Dispatcher ç©ºè½½ï¼Œè¿›å…¥ä¼‘çœ : {sleep_time:.2f}s (Current: {self.current_sleep:.2f}s)")
        await asyncio.sleep(sleep_time)
        
        # æŒ‡æ•°å¢é•¿ (1.5x)
        if self.current_sleep < self.max_sleep:
            self.current_sleep = min(self.current_sleep * 1.5, self.max_sleep)

    def _reset_sleep(self):
        """é‡ç½®ä¼‘çœ """
        self.current_sleep = self.min_sleep

    async def _prefetch_entities(self, tasks):
        """é¢„çƒ­ Telethon å®ä½“ç¼“å­˜ï¼Œé˜²æ­¢ Worker å‡ºç° Cache Miss å¯¼è‡´çš„ API å»¶è¿Ÿ"""
        current_chat_ids = set()
        for t in tasks:
            try:
                # å°è¯•ä» task_data æå– chat_id
                data = json.loads(t.task_data)
                cid = data.get('chat_id') or data.get('peer_id')
                if cid: 
                    try:
                        current_chat_ids.add(int(cid))
                    except: pass
            except: pass
            
        # å®šæœŸæ¸…ç†æœ¬åœ°å»é‡ç¼“å­˜ (æ¯å°æ—¶)ï¼Œé˜²æ­¢å†…å­˜å¢é•¿
        if time.time() - self._last_cache_clear > 3600:
            self._entity_cache.clear()
            self._last_cache_clear = time.time()

        # è¿‡æ»¤æ‰å·²ç»é¢„çƒ­è¿‡çš„ (å‡å°‘å¯¹ Telethon å†…éƒ¨ get_entity çš„é‡å¤è°ƒç”¨)
        to_fetch = current_chat_ids - self._entity_cache
        if not to_fetch:
            return
        
        logger.debug(f"Dispatcher æ­£åœ¨é¢„çƒ­ {len(to_fetch)} ä¸ªå®ä½“ç¼“å­˜...")
        for cid in to_fetch:
            try:
                # get_entity ä¼šè‡ªåŠ¨æ›´æ–° Telethon å†…éƒ¨ç¼“å­˜ï¼Œå®ƒæ˜¯çº¿ç¨‹/åç¨‹å®‰å…¨çš„
                await self.client.get_entity(cid)
                self._entity_cache.add(cid)
            except Exception as e:
                logger.warning(f"Entity prefetch failed for {cid}: {e}")
                # å¤±è´¥äº†ä¹Ÿè®°å½•ï¼Œé¿å…åœ¨åŒä¸€å°æ—¶å†…åå¤å°è¯•
                self._entity_cache.add(cid)

    def get_stats(self):
        """è·å–åˆ†å‘å™¨çŠ¶æ€"""
        uptime = time.time() - self.start_time if self.start_time else 0
        return {
            "total_dispatched": self.total_dispatched,
            "last_fetch": self.last_fetch_count,
            "current_queue_size": self.queue.qsize(),
            "uptime_sec": int(uptime),
            "throughput_per_min": int(self.total_dispatched / (uptime / 60)) if uptime > 60 else 0
        }
