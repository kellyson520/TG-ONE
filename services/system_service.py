import logging
import asyncio
import os
import sys
import time
from pathlib import Path
from typing import Optional, Dict, Any
from core.config import settings

logger = logging.getLogger(__name__)

class SystemService:
    """
    Service for system-wide configurations and state.
    """
    def __init__(self):
        self._allow_registration = True # Default
        
    def get_allow_registration(self) -> bool:
        return self._allow_registration
        
    def set_allow_registration(self, value: bool):
        self._allow_registration = value
        logger.info(f"Registration allowed set to: {value}")

    def get_logs(self, lines: int = 50, log_type: str = "app") -> str:
        """ËØªÂèñÁ≥ªÁªüÊó•ÂøóÊúÄËøë N Ë°å"""
        if log_type == "error":
            log_file = settings.LOG_DIR / "error.log"
        else:
            log_file = settings.LOG_DIR / "app.log"
            
        if not log_file.exists():
            return "Log file not found."
            
        try:
            with open(log_file, "r", encoding="utf-8", errors="ignore") as f:
                all_lines = f.readlines()
                return "".join(all_lines[-lines:])
        except Exception as e:
            return f"Failed to read log: {e}"
    
    def get_log_file_path(self, log_type: str = "app") -> Optional[Path]:
        """Ëé∑ÂèñÊó•ÂøóÊñá‰ª∂Ë∑ØÂæÑ (Áî®‰∫é‰∏ãËΩΩ)"""
        if log_type == "error":
            log_file = settings.LOG_DIR / "error.log"
        else:
            log_file = settings.LOG_DIR / "app.log"
        if log_file.exists():
            return log_file
        return None

    async def backup_database(self) -> Dict:
        """
        ÂºÇÊ≠•ÊâßË°åÊï∞ÊçÆÂ∫ìÂ§á‰ªΩ
        """
        try:
            from repositories.backup import backup_database as _backup
            
            # Âú®Á∫øÁ®ãÊ±†‰∏≠ÊâßË°åÂêåÊ≠•Â§á‰ªΩÊìç‰Ωú
            loop = asyncio.get_running_loop()
            backup_path = await loop.run_in_executor(None, _backup)
            
            if backup_path and os.path.exists(backup_path):
                size = os.path.getsize(backup_path) / (1024 * 1024)
                return {
                    "success": True, 
                    "path": backup_path, 
                    "size_mb": size
                }
            else:
                return {
                    "success": False, 
                    "error": "Backup function returned empty path"
                }
        except Exception as e:
            logger.error(f"Backup failed: {e}")
            return {
                "success": False, 
                "error": str(e)
            }

    async def run_db_optimization(self, deep: bool = False) -> Dict[str, Any]:
        """ËøêË°åÊï∞ÊçÆÂ∫ì‰ºòÂåñ (SQLite PRAGMA optimize/VACUUM)"""
        try:
            from models.models import AsyncSessionManager, cleanup_old_logs
            from sqlalchemy import text
            import time
            
            start_time = time.time()
            async with AsyncSessionManager() as session:
                if deep:
                    # Deep Ê®°ÂºèÔºöÊ∏ÖÁêÜÁ¢éÁâá
                    # Ê≥®ÊÑèÔºöVACUUM ‰∏çËÉΩÂú®‰∫ãÂä°‰∏≠ËøêË°åÔºå‰ΩÜÂú® SQLAlchemy ÂºÇÊ≠•‰∏ãÈúÄË∞®ÊÖéÂ§ÑÁêÜ
                    # ËøôÈáåÊàë‰ª¨‰ΩøÁî®ÂêåÊ≠•ÂºïÊìéÁöÑÊñπÊ≥ï‰Ωú‰∏∫ÂèÇËÄÉÔºåÊàñËÄÖÁõ¥Êé•ÈÄöËøá session ÊâßË°å
                    await session.execute(text("VACUUM;"))
                    logger.info("Database VACUUM completed.")
                else:
                    # Standard Ê®°ÂºèÔºö‰ºòÂåñÊü•ËØ¢ËÆ°Âàí
                    await session.execute(text("PRAGMA optimize;"))
                
                # Êó†ËÆ∫Âì™ÁßçÊ®°ÂºèÈÉΩÊõ¥Êñ∞ÁªüËÆ°‰ø°ÊÅØ
                await session.execute(text("ANALYZE;"))
                await session.commit()
            
            # Ê∏ÖÁêÜÊóßÊó•Âøó (ÊöÇÂÆö 30 Â§©)
            deleted_logs = 0
            if deep:
                from functools import partial
                import asyncio
                loop = asyncio.get_running_loop()
                deleted_logs = await loop.run_in_executor(None, partial(cleanup_old_logs, 30))
            
            return {
                "success": True,
                "duration": round(time.time() - start_time, 2),
                "deep": deep,
                "deleted_logs": deleted_logs,
                "message": f"Database optimization ({'VACUUM' if deep else 'PRAGMA optimize'} + ANALYZE) completed."
            }
        except Exception as e:
            logger.error(f"DB Optimization failed: {e}")
            return {"success": False, "error": str(e)}

class GuardService:
    """
    Guard service for hot-reloading and system health monitoring.
    Fully asynchronous implementation.
    """
    def __init__(self):
        self._stop_event = asyncio.Event()
        self._last_mtimes = {}
        self._watch_paths = [
            settings.BASE_DIR / ".env",
            settings.BASE_DIR / "main.py",
            settings.BASE_DIR / "core",
            settings.BASE_DIR / "services",
            settings.BASE_DIR / "web_admin"
        ]
        # Maintenance settings
        self._temp_guard_max = settings.TEMP_GUARD_MAX
        self._temp_guard_path = settings.TEMP_DIR
        self._memory_limit_mb = 500 # Default limit

    def start_guards(self):
        """Deprecated: Use start_guards_async instead."""
        pass
        
    async def start_guards_async(self):
        """ÂêØÂä®ÊâÄÊúâÂºÇÊ≠•ÂÆàÊä§‰ªªÂä°"""
        logger.info("üöÄ Initializing All System Guards (Async)...")
        self._stop_event.clear()
        
        # ËÆ∞ÂΩïÂàùÂßãÊñá‰ª∂Êó∂Èó¥
        self._update_mtimes()
        
        # ‰ΩøÁî® exception_handler ÊàñËÄÖ gather ÂêØÂä®ÊâÄÊúâËÉåÊôØ‰ªªÂä°
        # Êàë‰ª¨ËøôÈáåËÆ©ÂÆÉ‰ª¨‰Ωú‰∏∫ÈïøÈ©ª‰ªªÂä°ËøêË°å
        tasks = [
            self.start_config_guard(),
            self.start_memory_guard(),
            self.start_db_health_guard(),
            self.start_temp_guard(),
            self.start_file_watcher_guard()
        ]
        
        # ÂêØÂä®ËÉåÊôØ‰ªªÂä°
        for task in tasks:
            asyncio.create_task(task)
            
        logger.info("‚úÖ All Guards initiated.")

    def stop_guards(self):
        """ÂÅúÊ≠¢ÊâÄÊúâÂÆàÊä§ÈÄªËæë‰ø°Âè∑"""
        logger.info("Stopping System Guards...")
        self._stop_event.set()

    async def start_config_guard(self):
        """ÂºÇÊ≠•ÈÖçÁΩÆÂêåÊ≠•ÂÆàÊä§‰ªªÂä°"""
        logger.info("[guard] Config hot-load guard initiated.")
        while not self._stop_event.is_set():
            try:
                await asyncio.sleep(60)
                from core.config_initializer import load_dynamic_config_from_db
                await load_dynamic_config_from_db(settings)
            except Exception as e:
                logger.error(f"[guard-config] Error: {e}")

    async def start_memory_guard(self):
        """ÂºÇÊ≠•ÂÜÖÂ≠òÂèäÂ¢ìÁ¢ëÂåñÁª¥Êä§‰ªªÂä°"""
        logger.info("[guard] Memory guard initiated (Limit: {}MB).".format(self._memory_limit_mb))
        import gc
        import psutil
        from core.helpers.tombstone import tombstone
        
        check_interval = 30
        gc_interval = 1800
        last_gc = time.time()
        
        while not self._stop_event.is_set():
            try:
                now = time.time()
                # 1. ÂÆöÊó∂ GC
                if now - last_gc > gc_interval:
                    unreachable = gc.collect()
                    if unreachable > 0:
                        logger.debug(f"[guard-mem] GC collected {unreachable} objects")
                    last_gc = now
                
                # 2. ÂÜÖÂ≠òÈòàÂÄºÊ£ÄÊü•
                try:
                    process = psutil.Process()
                    rss_mb = process.memory_info().rss / 1024 / 1024
                    
                    if rss_mb > self._memory_limit_mb and not tombstone._is_frozen:
                        logger.warning(f"[guard-mem] Memory threshold exceeded ({rss_mb:.2f}MB > {self._memory_limit_mb}MB)")
                        await tombstone.freeze()
                    elif rss_mb < (self._memory_limit_mb * 0.7) and tombstone._is_frozen:
                        # ÂÜÖÂ≠òÈôç‰∏ãÊù•ÂêéÂ∞ùËØïÂ§çËãè
                        await tombstone.resurrect()
                except Exception as e:
                    logger.error(f"[guard-mem] Memory check error: {e}")
                
                await asyncio.sleep(check_interval)
            except Exception as e:
                logger.error(f"[guard-mem] Error: {e}")
                await asyncio.sleep(60)

    async def start_temp_guard(self):
        """ÂºÇÊ≠•‰∏¥Êó∂Êñá‰ª∂Ê∏ÖÁêÜÂÆàÊä§‰ªªÂä°"""
        logger.info("[guard] Temp directory guard initiated (Limit: {}GB).".format(self._temp_guard_max // 1024**3))
        while not self._stop_event.is_set():
            try:
                if self._temp_guard_path.exists():
                    files = []
                    total_size = 0
                    for f in self._temp_guard_path.rglob('*'):
                        if f.is_file():
                            try:
                                stat = f.stat()
                                total_size += stat.st_size
                                files.append((stat.st_mtime, stat.st_size, f))
                            except OSError:
                                pass
                    
                    if total_size > self._temp_guard_max:
                        # ÊåâÊó∂Èó¥ÂçáÂ∫èÊéíÂ∫èÔºàÊúÄÊóßÁöÑÂú®ÂâçÔºâ
                        files.sort(key=lambda x: x[0])
                        deleted_size = 0
                        target_size = total_size - self._temp_guard_max
                        deleted_count = 0
                        
                        for _, size, f in files:
                            if deleted_size >= target_size:
                                break
                            try:
                                if f.exists():
                                    f.unlink()
                                    deleted_size += size
                                    deleted_count += 1
                            except Exception:
                                pass
                        
                        if deleted_count > 0:
                            logger.info(f"[guard-temp] Cleaned {deleted_count} files, freed {deleted_size/1024/1024:.2f}MB")
                
                await asyncio.sleep(3600) # ÊØèÂ∞èÊó∂Ê£ÄÊü•
            except Exception as e:
                logger.error(f"[guard-temp] Error: {e}")
                await asyncio.sleep(3600)

    async def start_db_health_guard(self):
        """ÂºÇÊ≠•Êï∞ÊçÆÂ∫ìÂÅ•Â∫∑Ê£ÄÊü•"""
        logger.info("[guard] DB health monitor initiated.")
        from repositories.health_check import DatabaseHealthManager, settings as db_settings
        if not db_settings.ENABLE_DB_HEALTH_CHECK:
            return

        while not self._stop_event.is_set():
            try:
                await asyncio.sleep(4 * 3600)
                db_url = db_settings.DATABASE_URL
                if db_url.startswith("sqlite"):
                    path_str = db_url.split("///")[-1]
                    db_path = Path(db_settings.BASE_DIR) / path_str
                    manager = DatabaseHealthManager(str(db_path))
                    if not manager.check_health():
                        logger.critical("[guard-db] RUNTIME DB CORRUPTION DETECTED!")
            except Exception as e:
                logger.error(f"[guard-db] Error: {e}")

    async def start_file_watcher_guard(self):
        """ÂºÇÊ≠•Êñá‰ª∂ÂèòÂåñÁõëÊéß (ÁÉ≠ÈáçÂêØ)"""
        logger.info("[guard] File watcher guard initiated.")
        while not self._stop_event.is_set():
            try:
                changed = await asyncio.to_thread(self._check_changes)
                if changed:
                    logger.info(f"[guard-watcher] Detected change: {changed}. Triggering hot-restart...")
                    await asyncio.sleep(1)
                    await self._restart_process_async()
                await asyncio.sleep(5) # ÊØè5ÁßíÊ£ÄÊü•‰∏ÄÊ¨°
            except Exception as e:
                logger.error(f"[guard-watcher] Error: {e}")
                await asyncio.sleep(10)

    def _update_mtimes(self):
        for path in self._watch_paths:
            if not path.exists(): continue
            if path.is_file():
                self._last_mtimes[str(path)] = path.stat().st_mtime
            else:
                for p in path.glob("**/*.py"):
                    self._last_mtimes[str(p)] = p.stat().st_mtime

    def _check_changes(self) -> Optional[str]:
        for path in self._watch_paths:
            if not path.exists(): continue
            if path.is_file():
                mtime = path.stat().st_mtime
                if str(path) not in self._last_mtimes or mtime > self._last_mtimes[str(path)]:
                    self._last_mtimes[str(path)] = mtime
                    return str(path)
            else:
                for p in path.glob("**/*.py"):
                    mtime = p.stat().st_mtime
                    if str(p) not in self._last_mtimes or mtime > self._last_mtimes[str(p)]:
                        self._last_mtimes[str(p)] = mtime
                        return str(p)
        return None

    async def _restart_process_async(self):
        """ÂºÇÊ≠•Ëß¶ÂèëÈáçÂêØ"""
        logger.info("Triggering graceful restart...")
        from core.shutdown import get_shutdown_coordinator
        coordinator = get_shutdown_coordinator()
        try:
            await coordinator.shutdown()
            sys.exit(0)
        except Exception as e:
            logger.error(f"Graceful restart failed: {e}")
            sys.exit(1)

    def trigger_restart(self):
        asyncio.create_task(self._restart_process_async())


system_service = SystemService()
guard_service = GuardService()
