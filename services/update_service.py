import asyncio
import logging
import os
import subprocess
import sys
import json
import urllib.parse
from pathlib import Path
from typing import Optional, Tuple, Dict
from datetime import datetime

from core.config import settings
from services.system_service import guard_service
from core.container import container

logger = logging.getLogger(__name__)

# å®˜æ–¹è®¤è¯çš„ä»“åº“åœ°å€
OFFICIAL_REPO = "kellyson520/TG-ONE"

# é€€å‡ºç çº¦å®š
EXIT_CODE_UPDATE = 10  # è¯·æ±‚ç³»ç»Ÿçº§æ›´æ–°

class UpdateService:
    """
    é«˜å¯é æ€§è”ç½‘æ›´æ–°æœåŠ¡ (Advanced UpdateService)
    å‚è€ƒæˆç†Ÿæ–¹æ¡ˆï¼šæ”¯æŒç½‘ç»œé¢„æ£€ã€åŸå­æ›´æ–°ã€ä¾èµ–è‡ªåŠ¨åŒæ­¥åŠå›æ»šä¿æŠ¤ã€‚
    """
    
    def __init__(self):
        self._git_available = self._check_git_installed()
        self._is_git_repo = self._git_available and (settings.BASE_DIR / ".git").exists()
        self._stop_event = asyncio.Event()
        self._is_updating = False
        self._state_file = settings.BASE_DIR / "data" / "update_state.json"
        self._bus = None
        self._tasksList = []  # ç®¡ç†æœ¬æœåŠ¡å¯åŠ¨çš„ä»»åŠ¡
        
        # ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨
        self._state_file.parent.mkdir(parents=True, exist_ok=True)

    def set_bus(self, bus):
        """æ³¨å…¥äº‹ä»¶æ€»çº¿"""
        self._bus = bus
        logger.debug("UpdateService äº‹ä»¶æ€»çº¿å·²æ³¨å…¥")

    async def _emit_event(self, name: str, data: dict):
        """è§¦å‘ç³»ç»Ÿäº‹ä»¶"""
        if self._bus:
            await self._bus.publish(name, data)
        else:
            logger.debug(f"äº‹ä»¶æ€»çº¿ä¸å¯ç”¨ï¼Œäº‹ä»¶ {name} å·²å°è¯•ç¼“å­˜ï¼ˆå°šæœªå®ç°ï¼‰")

    def _check_git_installed(self) -> bool:
        """æ£€æŸ¥ç³»ç»Ÿç¯å¢ƒä¸­æ˜¯å¦å®‰è£…äº† Git"""
        import shutil
        return shutil.which("git") is not None

    async def get_current_version(self) -> str:
        """è·å–å½“å‰ç³»ç»Ÿç‰ˆæœ¬ (Git SHA æˆ– çŠ¶æ€æ–‡ä»¶è®°å½•)"""
        if self._is_git_repo:
            try:
                process = await asyncio.create_subprocess_exec(
                    "git", "rev-parse", "--short", "HEAD",
                    cwd=str(settings.BASE_DIR),
                    stdout=asyncio.subprocess.PIPE,
                    stderr=asyncio.subprocess.PIPE
                )
                out, _ = await process.communicate()
                if process.returncode == 0:
                    return out.decode().strip()
            except Exception:
                pass
        
        # Fallback to state
        state = self._get_state()
        return state.get("current_version", "")[:8]

    def _get_state(self) -> Dict:
        """ä»çŠ¶æ€æ–‡ä»¶è¯»å–æ›´æ–°å†å²"""
        if self._state_file.exists():
            try:
                return json.loads(self._state_file.read_text())
            except Exception as e:
                logger.warning(f'å·²å¿½ç•¥é¢„æœŸå†…çš„å¼‚å¸¸: {e}' if 'e' in locals() else 'å·²å¿½ç•¥é™é»˜å¼‚å¸¸')
        return {}

    def _save_state(self, state: Dict):
        """ä¿å­˜æ›´æ–°çŠ¶æ€"""
        try:
            self._state_file.write_text(json.dumps(state, indent=4))
        except Exception as e:
            logger.error(f"ä¿å­˜æ›´æ–°çŠ¶æ€å¤±è´¥: {e}")

    async def _check_network(self) -> bool:
        """ç½‘ç»œé¢„æ£€ (æµ‹è¯• GitHub è¿é€šæ€§)"""
        try:
            import socket
            loop = asyncio.get_running_loop()
            try:
                # å°è¯•è§£æåœ°å€ï¼Œæµ‹è¯• DNS å’ŒåŸºç¡€ç½‘ç»œ
                await loop.run_in_executor(None, lambda: socket.gethostbyname("github.com"))
                return True
            except Exception:
                return False
        except Exception:
            return False

    async def trigger_update(self, target_version: str = "origin/main"):
        """
        [é˜¶æ®µ1] è§¦å‘æ›´æ–°ï¼šå¤‡ä»½DB -> å†™é” -> é€€å‡ºè¿›ç¨‹
        è¿™æ˜¯å·¥ä¸šçº§åŒå±‚çŠ¶æ€æœºçš„ç¬¬ä¸€é˜¶æ®µï¼Œç”± Python å±‚æ‰§è¡Œ
        target_version: å¯ä»¥æ˜¯ commit SHA, branch name æˆ– tag
        """
        try:
            logger.info(f"ğŸ›¡ï¸ [æ›´æ–°] æ­£åœ¨å¯åŠ¨æ›´æ–°åºåˆ— (ç›®æ ‡: {target_version})...")
            
            # 1. æ•°æ®åº“åŸå­å¤‡ä»½
            db_backup_path = None
            db_file = settings.BASE_DIR / "data" / "bot.db"
            if db_file.exists():
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                db_backup_path = self._state_file.parent / "backups" / "auto_update" / f"bot.db.{timestamp}.bak"
                db_backup_path.parent.mkdir(parents=True, exist_ok=True)
                
                import shutil
                shutil.copy2(db_file, db_backup_path)
                logger.info(f"âœ… [æ›´æ–°] æ•°æ®åº“å·²å¤‡ä»½è‡³ {db_backup_path}")
                
                # æ—‹è½¬å¤‡ä»½
                self._rotate_backups(db_backup_path.parent, "bot.db.*.bak", settings.UPDATE_BACKUP_LIMIT)

            # 2. å†™å…¥çŠ¶æ€é”
            state = {
                "status": "processing",
                "start_time": datetime.now().isoformat(),
                "db_backup": str(db_backup_path) if db_backup_path else None,
                "version": target_version
            }
            
            # ç¡®ä¿é”æ–‡ä»¶ç›®å½•å­˜åœ¨
            lock_file = settings.BASE_DIR / "data" / "UPDATE_LOCK.json"
            lock_file.parent.mkdir(parents=True, exist_ok=True)
            
            with open(lock_file, "w", encoding="utf-8") as f:
                json.dump(state, f, indent=2)
            
            # å‘é€å¯åŠ¨é€šçŸ¥
            await self._emit_event("SYSTEM_ALERT", {"message": f"ğŸš€ ç³»ç»Ÿæ›´æ–°/å›æ»šå·²è§¦å‘ (ç›®æ ‡: {target_version})ï¼Œæ­£åœ¨å‡†å¤‡ç¯å¢ƒå¹¶é‡å¯..."})
            
            # 3. é€€å‡ºè¿›ç¨‹ï¼Œç§»äº¤æ§åˆ¶æƒç»™ entrypoint.sh
            # æ­¤æ—¶ Web Server ä¼šåœæ­¢ï¼ŒSocket æ–­å¼€
            if container.lifecycle:
                container.lifecycle.shutdown(EXIT_CODE_UPDATE)
            else:
                sys.exit(EXIT_CODE_UPDATE)

        except SystemExit:
            raise
        except Exception as e:
            logger.error(f"âŒ [æ›´æ–°] å‡†å¤‡å·¥ä½œå¤±è´¥: {e}", exc_info=True)
            # æ¸…ç†é”æ–‡ä»¶
            lock_file = settings.BASE_DIR / "data" / "UPDATE_LOCK.json"
            if lock_file.exists():
                lock_file.unlink()
            raise RuntimeError("æ›´æ–°å‡†å¤‡å¤±è´¥")

    async def request_rollback(self):
        """
        è¯·æ±‚ç´§æ€¥å›æ»šã€‚
        è®¾ç½®é”æ–‡ä»¶çŠ¶æ€ä¸º rollback_requested å¹¶é€€å‡ºï¼Œç”±å®ˆæŠ¤è¿›ç¨‹æ¥ç®¡æ‰§è¡Œå›æ»šã€‚
        """
        try:
            logger.critical("ğŸš‘ [æ›´æ–°] æ”¶åˆ°æ‰‹åŠ¨å›æ»šè¯·æ±‚ï¼Œæ­£åœ¨å‡†å¤‡ç¯å¢ƒ...")
            
            # å†™é”
            state = {
                "status": "rollback_requested",
                "start_time": datetime.now().isoformat(),
                "version": "rollback"
            }
            lock_file = settings.BASE_DIR / "data" / "UPDATE_LOCK.json"
            lock_file.parent.mkdir(parents=True, exist_ok=True)
            
            with open(lock_file, "w", encoding="utf-8") as f:
                json.dump(state, f, indent=2)
                
            await self._emit_event("SYSTEM_ALERT", {"message": "ğŸš‘ ç³»ç»Ÿç´§æ€¥å›æ»šå·²è§¦å‘ï¼Œæ­£åœ¨é‡å¯æ¢å¤..."})
            if container.lifecycle:
                container.lifecycle.shutdown(EXIT_CODE_UPDATE)
            else:
                sys.exit(EXIT_CODE_UPDATE)
        except SystemExit:
            raise
        except Exception as e:
            logger.error(f"âŒ [å›æ»š] è¯·æ±‚å¤±è´¥: {e}")
            raise RuntimeError("å›æ»šè¯·æ±‚å¤±è´¥")

    async def post_update_bootstrap(self):
        """
        [é˜¶æ®µ2] å¯åŠ¨å¼•å¯¼ï¼šæ£€æŸ¥é” -> DBè¿ç§» -> æ¸…ç†é”
        """
        lock_file = settings.BASE_DIR / "data" / "UPDATE_LOCK.json"
        if not lock_file.exists():
            return

        logger.info("ğŸ”§ [æ›´æ–°] æ£€æµ‹åˆ°æœªå®Œæˆçš„æ›´æ–°ã€‚æ­£åœ¨æ‰§è¡Œåç½®æ›´æ–°ä»»åŠ¡...")
        try:
            with open(lock_file, "r", encoding="utf-8") as f:
                state = json.load(f)

            logger.info("âš™ï¸ [æ›´æ–°] æ­£åœ¨åº”ç”¨æ•°æ®åº“è¿ç§»...")
            alembic_ini = settings.BASE_DIR / "alembic.ini"
            if alembic_ini.exists():
                try:
                    process = await asyncio.create_subprocess_exec(
                        "alembic", "upgrade", "head",
                        stdout=asyncio.subprocess.PIPE,
                        stderr=asyncio.subprocess.PIPE,
                        cwd=str(settings.BASE_DIR)
                    )
                    stdout, stderr = await process.communicate()
                    
                    if process.returncode != 0:
                        err_msg = (stderr or stdout).decode(encoding='utf-8', errors='ignore')
                        logger.error(f"ğŸ”¥ [æ›´æ–°] æ•°æ®åº“è¿ç§»å¤±è´¥ (Code: {process.returncode}):\n{err_msg}")
                        if state.get("db_backup"):
                            self._rollback_db(state["db_backup"])
                    else:
                        logger.info("âœ… [æ›´æ–°] æ•°æ®åº“è¿ç§»æˆåŠŸã€‚")
                        
                        health_ok, health_msg = await self._run_system_health_check()
                        if not health_ok:
                            logger.error(f"ğŸš‘ [æ›´æ–°] å¥åº·æ£€æŸ¥å¤±è´¥: {health_msg}")
                        else:
                            logger.info("âœ… [æ›´æ–°] æ›´æ–°åçš„å¥åº·æ£€æŸ¥å·²é€šè¿‡ã€‚")
                except Exception as e:
                    logger.error(f"ğŸ”¥ [æ›´æ–°] æ‰§è¡Œ Alembic è¿ç§»æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
                    if state.get("db_backup"):
                        self._rollback_db(state["db_backup"])
            else:
                logger.warning("âš ï¸ [æ›´æ–°] æœªå‘ç° alembic.iniï¼Œè·³è¿‡æ•°æ®åº“è¿ç§»ã€‚")

        except Exception as e:
            logger.error(f"âŒ [æ›´æ–°] å¼•å¯¼ä»»åŠ¡å¤±è´¥: {e}")
        finally:
            try:
                verify_lock = settings.BASE_DIR / "data" / "UPDATE_VERIFYING.json"
                if lock_file.exists():
                    import shutil
                    shutil.move(str(lock_file), str(verify_lock))
                    logger.info("âœ… [æ›´æ–°] æ•°æ®åº“åç½®å¼•å¯¼å®Œæˆï¼Œå·²åˆ‡æ¢è‡³ç¨³å®šæ€§è§‚å¯Ÿæ¨¡å¼ã€‚")
            except Exception as e:
                logger.error(f"åˆ‡æ¢æ›´æ–°é”çŠ¶æ€å¤±è´¥: {e}")
                if lock_file.exists(): lock_file.unlink()

    def _rollback_db(self, backup_path: str):
        """å›æ»šæ•°æ®åº“åˆ°å¤‡ä»½ç‰ˆæœ¬"""
        logger.warning(f"âª [æ›´æ–°] æ­£åœ¨ä»å¤‡ä»½å›æ»šæ•°æ®åº“: {backup_path}...")
        try:
            import shutil
            backup_file = Path(backup_path)
            db_file = settings.BASE_DIR / "data" / "bot.db"
            
            if backup_file.exists():
                shutil.copy2(backup_file, db_file)
                logger.info("âœ… [æ›´æ–°] æ•°æ®åº“å›æ»šå®Œæˆã€‚")
            else:
                logger.error("â˜ ï¸ [æ›´æ–°] æ•°æ®åº“å¤‡ä»½æ–‡ä»¶ä¸¢å¤±ï¼")
        except Exception as e:
            logger.critical(f"â˜ ï¸ [æ›´æ–°] ä¸¥é‡é”™è¯¯ï¼šæ•°æ®åº“å›æ»šå¤±è´¥: {e}")

    async def start_periodic_check(self):
        """å¯åŠ¨æ›´æ–°æ£€æŸ¥æœåŠ¡"""
        # å¯åŠ¨æ—¶é¦–å…ˆéªŒè¯æ›´æ–°å¥åº·åº¦ (å¤„ç†æ‰‹åŠ¨æ›´æ–°åçš„å´©æºƒè‡ªæ„ˆ)
        await self.verify_update_health()

        # 1. å§‹ç»ˆå¯åŠ¨: å¤–éƒ¨ä¿¡å·ç›‘å¬
        t1 = asyncio.create_task(self._watch_external_signals(), name="update_signal_watcher")
        self._tasksList.append(t1)

        # 2. æ¡ä»¶å¯åŠ¨: è‡ªåŠ¨æ›´æ–°æ£€æŸ¥
        if not settings.AUTO_UPDATE_ENABLED:
            logger.info("è‡ªåŠ¨æ›´æ–°åŠŸèƒ½å·²å…³é—­ (ä»…å“åº”æ‰‹åŠ¨/å¤–éƒ¨æŒ‡ä»¤)ã€‚")
            return

        logger.info(f"è‡ªåŠ¨æ›´æ–°å·²å¼€å¯ï¼Œæ£€æŸ¥é—´éš”: {settings.UPDATE_CHECK_INTERVAL} ç§’")
        # å¯åŠ¨å‘¨æœŸæ€§æ£€æŸ¥å¾ªç¯
        t2 = asyncio.create_task(self._run_periodic_update_check(), name="periodic_update_check")
        self._tasksList.append(t2)

    async def _watch_external_signals(self):
        """ç›‘å¬å¤–éƒ¨æ›´æ–°ä¿¡å· (UPDATE_LOCK.json)"""
        lock_file = settings.BASE_DIR / "data" / "UPDATE_LOCK.json"
        logger.info("ğŸ“¡ [UpdateService] å¤–éƒ¨ä¿¡å·ç›‘å¬å™¨å·²å°±ç»ª")
        
        while not self._stop_event.is_set():
            try:
                try:
                    await asyncio.wait_for(self._stop_event.wait(), timeout=5.0)
                    break 
                except asyncio.TimeoutError:
                    pass

                if not lock_file.exists():
                    continue

                try:
                    content = json.loads(lock_file.read_text(encoding='utf-8'))
                    status = content.get("status")
                    
                    if status in ["processing", "rollback_requested"]:
                        logger.warning(f"ğŸ“¡ [UpdateService] æ£€æµ‹åˆ°å¤–éƒ¨æ›´æ–°ä¿¡å· (Status: {status})ï¼Œæ­£åœ¨è¿›è¡Œå—æ§é‡å¯...")
                        
                        # å¦‚æœç³»ç»Ÿå·²ç»åœ¨å…³é—­æµç¨‹ä¸­ï¼Œæˆ‘ä»¬åªå°è¯•æ›´æ–°é€€å‡ºç ï¼Œä¸å†å‘é€äº‹ä»¶ï¼ˆé˜²æ­¢ EventBus å…³é—­å¯¼è‡´çš„æŒ‚èµ·ï¼‰
                        is_closing = False
                        if container.lifecycle and container.lifecycle.stop_event.is_set():
                            is_closing = True
                            
                        if not is_closing:
                            await self._emit_event("SYSTEM_ALERT", {"message": "ğŸ“¡ æ£€æµ‹åˆ°å¤–éƒ¨æ›´æ–°æŒ‡ä»¤ï¼Œç³»ç»Ÿæ­£åœ¨é‡å¯ä»¥åº”ç”¨å˜æ›´..."})
                        
                        if container.lifecycle:
                            container.lifecycle.shutdown(EXIT_CODE_UPDATE)
                        else:
                            sys.exit(EXIT_CODE_UPDATE)
                       
                        # ç«‹å³é€€å‡ºç›‘å¬å¾ªç¯
                        break
                        
                except json.JSONDecodeError:
                    pass
                except SystemExit:
                    raise
                except Exception:
                    pass

            except SystemExit:
                raise
            except Exception as e:
                logger.error(f"ä¿¡å·ç›‘å¬å¼‚å¸¸: {type(e).__name__}: {e}")
                # Backoff with interruptibility
                try:
                    await asyncio.wait_for(self._stop_event.wait(), timeout=10.0)
                    break
                except asyncio.TimeoutError:
                    pass

    async def _run_periodic_update_check(self):
        """æ‰§è¡Œå‘¨æœŸæ€§è‡ªåŠ¨æ›´æ–°æ£€æŸ¥"""
        while not self._stop_event.is_set():
            try:
                try:
                    await asyncio.wait_for(self._stop_event.wait(), timeout=settings.UPDATE_CHECK_INTERVAL)
                    break  # Stop signaled
                except asyncio.TimeoutError:
                    pass   # Timeout, continue check

                # ç½‘ç»œæ£€æŸ¥ï¼Œä¸é€šåˆ™è·³è¿‡æœ¬æ¬¡å¾ªç¯
                if not await self._check_network():
                    logger.debug("ç½‘ç»œè¿æ¥å¼‚å¸¸ï¼Œè·³è¿‡æœ¬æ¬¡æ›´æ–°æ£€æŸ¥ã€‚")
                    continue

                has_update, remote_ver = await self.check_for_updates(force=False)
                if has_update:
                    logger.info(f"ğŸ†• [æ›´æ–°] å‘ç°æ–°ç‰ˆæœ¬ (ç›®æ ‡: {remote_ver})ï¼Œæ­£åœ¨å¯åŠ¨é«˜å¯é æ‰§è¡Œé€»è¾‘...")
                    # æ³¨æ„: è¿™é‡Œè°ƒç”¨ perform_update ä¼šç›´æ¥ä¸‹è½½ä»£ç å¹¶è¦†ç›–ï¼Œ
                    # æˆåŠŸå guard_service.trigger_restart() ä¼šé‡å¯ã€‚
                    success, msg = await self.perform_update()
                    if success:
                        logger.info("âœ… [æ›´æ–°] åŸå­åŒæ­¥å®Œæˆï¼Œæ­£åœ¨è§¦å‘æ™ºèƒ½é‡å¯...")
                        guard_service.trigger_restart()
                    else:
                        logger.error(f"âŒ [æ›´æ–°] æ ¸å¿ƒæµç¨‹å¤±è´¥: {msg}")
            except Exception as e:
                logger.error(f"æ›´æ–°ç›‘æ§è¿è¡Œå‡ºé”™: {e}")
                try:
                    await asyncio.wait_for(self._stop_event.wait(), timeout=3600)
                    break
                except asyncio.TimeoutError:
                    pass

    async def verify_update_health(self):
        """
        éªŒè¯æ›´æ–°åçš„ç³»ç»Ÿå¥åº·çŠ¶å†µã€‚
        å¦‚æœç³»ç»Ÿå¯åŠ¨ååœ¨çŸ­æ—¶é—´å†…å´©æºƒï¼Œä¸‹æ¬¡å¯åŠ¨ä¼šæ£€æµ‹å¹¶å¤„ç†è¿ç»­å¤±è´¥ã€‚
        """
        state = self._get_state()
        status = state.get("status")
        
        if status == "shell_failed":
            logger.error(f"âŒ [æ›´æ–°] Shell æ›´æ–°å¤±è´¥: {state.get('error')}")
            await self._emit_event("ERROR_SYSTEM", {"module": "Update", "error": state.get("error", "æœªçŸ¥ Shell é”™è¯¯")})
            # å¤„ç†å®Œåé‡ç½®çŠ¶æ€ï¼Œé˜²æ­¢é‡å¤é€šçŸ¥
            state["status"] = "failed_processed"
            self._save_state(state)
            return

        if status == "critical_failed":
            logger.critical(f"â˜ ï¸ [æ›´æ–°] å…³é”®æ€§æ•…éšœ: {state.get('error')}")
            await self._emit_event("ERROR_SYSTEM", {"module": "Update", "error": f"ğŸš¨ ä¸¥é‡æ›´æ–°äº‹æ•…: {state.get('error', 'æœªçŸ¥é”™è¯¯')}"})
            state["status"] = "failed_processed"
            self._save_state(state)
            return

        if status == "restarting":
            # å¢åŠ å¤±è´¥è®¡æ•°
            fail_count = state.get("fail_count", 0) + 1
            state["fail_count"] = fail_count
            
            if fail_count >= 3:
                logger.critical(f"ğŸ˜± [è­¦å‘Š] ç³»ç»Ÿåœ¨æ›´æ–°åè¿ç»­ {fail_count} æ¬¡å¯åŠ¨å¤±è´¥ï¼æ­£åœ¨å°è¯•ç´§æ€¥å›æ»šè‡³ä¸Šä¸ªç¨³å®šç‰ˆæœ¬...")
                success, msg = await self.rollback()
                if success:
                    # å›æ»šåé‡ç½®çŠ¶æ€å¹¶å†æ¬¡é‡å¯
                    state["status"] = "rolled_back"
                    state["fail_count"] = 0
                    self._save_state(state)
                    await self._emit_event("ERROR_SYSTEM", {"module": "Update", "error": f"ç³»ç»Ÿæ›´æ–°åå¤šæ¬¡å¯åŠ¨å¤±è´¥ï¼Œå·²è§¦å‘ç´§æ€¥å›æ»šã€‚"})
                    guard_service.trigger_restart()
                return

            self._save_state(state)
            logger.warning(f"â³ [æ›´æ–°] ç³»ç»Ÿæ­£å¤„äºè§‚å¯ŸæœŸ (å°è¯• {fail_count}/3)ã€‚è‹¥ 60s åä»è¿è¡Œæ­£å¸¸å°†æ ‡è®°æ›´æ–°æˆåŠŸã€‚")
            
            # å¼‚æ­¥è§‚å¯Ÿï¼Œå¦‚æœç³»ç»ŸåšæŒè¿è¡Œï¼Œåˆ™æ ‡è®°ä¸ºç¨³å®š
            asyncio.create_task(self._stabilize_after_delay(60))

    async def _stabilize_after_delay(self, seconds: int):
        """å»¶è¿Ÿæ ‡è®°ç³»ç»Ÿä¸ºç¨³å®šçŠ¶æ€"""
        await asyncio.sleep(seconds)
        state = self._get_state()
        if state.get("status") == "restarting":
            logger.info("ğŸ’ª [æ›´æ–°] ç³»ç»Ÿå·²ç¨³å®šè¿è¡Œè¶…è¿‡ 60sï¼Œæ›´æ–°éªŒè¯æˆåŠŸã€‚")
            state["status"] = "stable"
            state["fail_count"] = 0
            self._save_state(state)
            await self._emit_event("SYSTEM_ALERT", {"message": f"ğŸ‰ ç³»ç»Ÿå·²ç¨³å®šè¿è¡Œï¼Œæ›´æ–°ä»»åŠ¡æœ€ç»ˆç¡®è®¤å®Œæˆã€‚å½“å‰ç‰ˆæœ¬: {state.get('current_version', 'æœªçŸ¥')}"})

    async def get_update_history(self, limit: int = 10) -> list[dict]:
        """è·å–æ›´æ–°å†å² (Git commits)"""
        if not self._is_git_repo:
            return []
        
        try:
            # ä½¿ç”¨ git log è·å–å†å²
            process = await asyncio.create_subprocess_exec(
                "git", "log", f"-n", str(limit), "--pretty=format:%H|%an|%at|%s",
                cwd=str(settings.BASE_DIR),
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            out, err = await process.communicate()
            if process.returncode != 0:
                logger.error(f"Git æ—¥å¿—è·å–å¤±è´¥: {err.decode()}")
                return []
                
            lines = out.decode('utf-8', errors='ignore').strip().split('\n')
            
            history = []
            for line in lines:
                if not line or '|' not in line: continue
                parts = line.split('|', 3)
                if len(parts) < 4: continue
                sha, author, timestamp, msg = parts
                history.append({
                    "sha": sha,
                    "short_sha": sha[:8],
                    "author": author,
                    "timestamp": datetime.fromtimestamp(int(timestamp)).isoformat(),
                    "message": msg
                })
            return history
        except Exception as e:
            logger.error(f"è·å–æ›´æ–°å†å²å¤±è´¥: {e}")
            return []

    async def _run_system_health_check(self) -> Tuple[bool, str]:
        """æ‰§è¡Œç³»ç»Ÿå¥åº·æ£€æŸ¥ï¼Œç¡®è®¤æ›´æ–°åè¿è¡Œæ­£å¸¸"""
        try:
            # 1. æ£€æŸ¥æ•°æ®åº“
            try:
                from repositories.health_check import DatabaseHealthManager
                db_path = settings.BASE_DIR / "db" / "forward.db"
                manager = DatabaseHealthManager(str(db_path))
                if not manager.check_health():
                    return False, "æ•°æ®åº“å®Œæ•´æ€§æ ¡éªŒæœªé€šè¿‡"
            except Exception:
                # å¦‚æœ health_check å¯¼å…¥å¤±è´¥æˆ–è¿è¡Œå‡ºé”™ï¼Œå›æ»šæœ€åŸºç¡€çš„æ£€æŸ¥
                if not (settings.BASE_DIR / "db" / "forward.db").exists():
                    return False, "æ•°æ®åº“æ–‡ä»¶ä¸¢å¤±"
            
            # 2. æ£€æŸ¥ç½‘ç»œ
            if not await self._check_network():
                return False, "ç½‘ç»œè¿é€šæ€§å¼‚å¸¸"
                
            # 3. æ£€æŸ¥åŸºç¡€ç¯å¢ƒ
            if not (settings.BASE_DIR / "main.py").exists():
                return False, "æ ¸å¿ƒæ–‡ä»¶ä¸¢å¤±: main.py"
                
            return True, "ç³»ç»Ÿè¿è¡Œæ­£å¸¸"
        except Exception as e:
            return False, f"å¥åº·æ£€æŸ¥å¼‚å¸¸: {e}"

    async def check_for_updates(self, force: bool = False) -> Tuple[bool, str]:
        """åŸå­æ£€æŸ¥è¿œç¨‹ä»“åº“çŠ¶æ€"""
        # 0. ç°åº¦å‘å¸ƒè¿‡æ»¤ (å¦‚æœæ˜¯è‡ªåŠ¨è§¦å‘)
        if not force and not self._is_target_of_gray_release():
            # æ³¨æ„: å¦‚æœæ˜¯ç”¨æˆ·é€šè¿‡ Web æ‰‹åŠ¨ç‚¹æ›´æ–°ï¼Œåº”è¯¥ç»•è¿‡æ­¤æ£€æŸ¥ã€‚
            # è¿™é‡Œå…ˆå®ç°é€»è¾‘ï¼Œè°ƒç”¨æ–¹ï¼ˆstart_periodic_checkï¼‰ä¼šéšå«å—é™ã€‚
            return False, "æœªå‘½ä¸­ç°åº¦ç­–ç•¥"

        # å®‰å…¨æ£€æŸ¥ 1: éªŒè¯é…ç½®ä¸­çš„ URL æ˜¯å¦åˆæ³•
        if not self._verify_repo_safety(settings.UPDATE_REMOTE_URL):
            return False, "ä»“åº“åœ°å€æœªé€šè¿‡å®‰å…¨éªŒè¯ (é HTTPS æˆ–é GitHub)"

        check_result = False
        check_msg = ""
        remote_sha_candidate = ""

        if self._git_available and self._is_git_repo:
            check_result, check_msg = await self._check_via_git()
            remote_sha_candidate = check_msg if check_result else ""
        else:
            check_result, check_msg = await self._check_via_http()
            remote_sha_candidate = check_msg if check_result else ""

        # å®‰å…¨æ£€æŸ¥ 2: äº¤å‰éªŒè¯ (Cross-Verification)
        # å³ä½¿ Git/HTTP æ£€æŸ¥æˆåŠŸï¼Œä¹Ÿè¦ç”¨å®˜æ–¹ API å†æ¬¡ç¡®è®¤è¯¥ SHA æ˜¯å¦å±äºå®˜æ–¹ä»“åº“
        # è¿™èƒ½é˜²æ­¢ .git/config è¢«ç¯¡æ”¹æŒ‡å‘æ¶æ„æº
        if check_result and remote_sha_candidate:
            is_valid_sha = await self._cross_verify_sha(remote_sha_candidate)
            if not is_valid_sha:
                logger.critical(f"ğŸš¨ [å®‰å…¨é˜»æ–­] æ£€æµ‹åˆ° SHA æŒ‡çº¹ä¸åŒ¹é…ï¼è¿œç¨‹ç‰ˆæœ¬ {remote_sha_candidate} æœªåœ¨å®˜æ–¹ä»“åº“ {OFFICIAL_REPO} éªŒè¯é€šè¿‡ã€‚")
                return False, "å®‰å…¨æ ¡éªŒå¤±è´¥ï¼šç‰ˆæœ¬æŒ‡çº¹ä¸å®˜æ–¹æºä¸ç¬¦"

        return check_result, check_msg

    def _is_target_of_gray_release(self) -> bool:
        """åˆ¤æ–­å½“å‰å®ä¾‹æ˜¯å¦å‘½ä¸­ç°åº¦æ›´æ–°ç­–ç•¥ (åŸºäº USER_ID çš„ç¡®å®šæ€§éšæœº)"""
        if settings.UPDATE_CANARY_PROBABILITY >= 1.0:
            return True
        if settings.UPDATE_CANARY_PROBABILITY <= 0.0:
            return False
            
        import hashlib
        # ä½¿ç”¨ USER_ID ä½œä¸ºç§å­ï¼Œç¡®ä¿åŒä¸€è´¦å·åœ¨åŒä¸€ç‰ˆæœ¬ä¸‹çš„ç»“æœä¸€è‡´
        seed_base = f"update_gray_{settings.USER_ID or 'anon'}"
        seed = hashlib.md5(seed_base.encode()).hexdigest()
        val = int(seed[:8], 16) / 0xFFFFFFFF
        
        return val <= settings.UPDATE_CANARY_PROBABILITY

    async def _cross_verify_sha(self, sha_short: str) -> bool:
        """
        äº¤å‰éªŒè¯: è¿™é‡Œçš„é€»è¾‘æ˜¯ç»å¯¹ä¿¡ä»»'ç¡¬ç¼–ç 'çš„ OFFICIAL_REPOã€‚
        é€šè¿‡ç‹¬ç«‹çš„ HTTP é€šé“è®¿é—®å®˜æ–¹ APIï¼Œç¡®è®¤ sha_short æ˜¯å¦çœŸå®å­˜åœ¨äºå®˜æ–¹ main åˆ†æ”¯çš„å¤´éƒ¨ã€‚
        """
        try:
            import httpx
            # å§‹ç»ˆè®¿é—®ä»£ç é‡Œå†™æ­»çš„ OFFICIAL_REPOï¼Œæ— è§†é…ç½®æ–‡ä»¶çš„ URL
            api_url = f"https://api.github.com/repos/{OFFICIAL_REPO}/commits/{settings.UPDATE_BRANCH}"
            
            async with httpx.AsyncClient(timeout=5.0, follow_redirects=True) as client:
                resp = await client.get(api_url)
                if resp.status_code == 200:
                    official_sha = resp.json().get("sha", "")
                    # æ¯”å¯¹å‰ 8 ä½
                    sha_s = sha_short.strip()
                    official_s = official_sha[:len(sha_s)].strip()
                    if official_s and sha_s == official_s:
                        return True
                    logger.warning(f"äº¤å‰éªŒè¯ä¸ä¸€è‡´: Gitè·å–={sha_s}, å®˜æ–¹API={official_s}")
                    # å¦‚æœç½‘ç»œä¸é€šï¼Œä¸ºäº†é˜²æ­¢æ­»é”ï¼Œå¯ä»¥é€‰æ‹©æ”¾è¡Œæˆ–ä¸¥æ ¼é˜»æ–­ã€‚
                    # è€ƒè™‘åˆ°é«˜å¯é æ€§ï¼Œå¦‚æœç‰ˆæœ¬æå…¶ä¸åŒ¹é…ï¼Œå¯èƒ½éœ€è¦é˜»æ–­
                    return False
                else:
                    logger.warning(f"äº¤å‰éªŒè¯è·³è¿‡: æ— æ³•è¿æ¥å®˜æ–¹ API ({resp.status_code})")
                    return True 
        except Exception as e:
            logger.warning(f"äº¤å‰éªŒè¯å¼‚å¸¸: {e}")
            return True

    def _verify_repo_safety(self, url: str) -> bool:
        """éªŒè¯è¿œç¨‹ä»“åº“åœ°å€çš„å®‰å…¨æ€§"""
        try:
            parsed = urllib.parse.urlparse(url)
            # 1. å¼ºåˆ¶ HTTPS
            if parsed.scheme != "https":
                logger.warning(f"âš ï¸ [å®‰å…¨è­¦æŠ¥] æ‹’ç»ä½¿ç”¨éåŠ å¯†åè®®æ›´æ–°: {url}")
                return False
            
            # 2. æ£€æŸ¥æ˜¯å¦ä¸º GitHub (ç›®å‰ä¸»è¦æ”¯æŒ GitHub)
            if parsed.netloc != "github.com":
                logger.warning(f"âš ï¸ [å®‰å…¨æç¤º] æ›´æ–°æºé GitHub å®˜æ–¹åŸŸ: {parsed.netloc}")
                # æš‚æ—¶å…è®¸é GitHub ä½†è®°å½•è­¦å‘Š (æ ¹æ®ç”¨æˆ·éœ€æ±‚ï¼Œè¿™é‡Œå¯ä»¥æ›´ä¸¥æ ¼)
            
            # 3. å®˜æ–¹ä»“åº“æ¯”å¯¹
            normalized_url = url.replace("https://", "").replace("http://", "")
            if normalized_url.endswith(".git"):
                normalized_url = normalized_url[:-4]
            if normalized_url.startswith("github.com/"):
                 normalized_url = normalized_url[11:]

            if normalized_url != OFFICIAL_REPO:
                logger.warning(f"âš ï¸ [å®‰å…¨æç¤º] æ­£åœ¨ä½¿ç”¨éå®˜æ–¹ä»“åº“æ›´æ–°: {normalized_url} (å®˜æ–¹: {OFFICIAL_REPO})")
            
            return True
        except Exception:
            return False

    async def _check_via_git(self) -> Tuple[bool, str]:
        """é€šè¿‡ Git æŒ‡ä»¤æ£€æŸ¥æ›´æ–°"""

        try:
            # æ‰§è¡Œé™é»˜ Fetch å¹¶è®¾ç½®è¶…æ—¶
            process = await asyncio.create_subprocess_exec(
                "git", "fetch", "--quiet", "origin", settings.UPDATE_BRANCH,
                cwd=str(settings.BASE_DIR),
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            try:
                await asyncio.wait_for(process.wait(), timeout=30)
            except asyncio.TimeoutError:
                if process:
                    try:
                        process.kill()
                    except Exception as e:
                        logger.warning(f'å·²å¿½ç•¥é¢„æœŸå†…çš„å¼‚å¸¸: {e}' if 'e' in locals() else 'å·²å¿½ç•¥é™é»˜å¼‚å¸¸')
                return False, "ç½‘ç»œè·å–è¶…æ—¶"

            # 2. æ£€æŸ¥æœ¬åœ°æ˜¯å¦è½åäºè¿œç¨‹ (æ£€æŸ¥ HEAD..origin/branch çš„æäº¤æ•°)
            # ç†ç”±ï¼šå¦‚æœ local_id != remot_idï¼Œå¯èƒ½åªæ˜¯æœ¬åœ°é¢†å…ˆæˆ–åç¦»ã€‚
            # æˆ‘ä»¬ä»…åœ¨æœ¬åœ°ç¼ºå°‘è¿œç¨‹æäº¤æ—¶æç¤ºæ›´æ–°ã€‚
            check_proc = await asyncio.create_subprocess_exec(
                "git", "rev-list", f"HEAD..origin/{settings.UPDATE_BRANCH}", "--count",
                cwd=str(settings.BASE_DIR), stdout=asyncio.subprocess.PIPE
            )
            out, _ = await check_proc.communicate()
            behind_count = int(out.decode().strip() or 0)

            # è·å–è¿œç¨‹ SHA ç”¨äºå±•ç¤º
            remot_proc = await asyncio.create_subprocess_exec(
                "git", "rev-parse", f"origin/{settings.UPDATE_BRANCH}",
                cwd=str(settings.BASE_DIR), stdout=asyncio.subprocess.PIPE
            )
            r_out, _ = await remot_proc.communicate()
            remot_id = r_out.decode().strip()

            if behind_count > 0:
                return True, remot_id[:8]
            
            # å¦‚æœä¸è½åï¼ˆç›¸ç­‰ã€é¢†å…ˆæˆ–å®Œå…¨åˆ†å‰ä½†å·²åŒæ­¥ï¼‰ï¼Œåˆ™æ˜¾ç¤ºå½“å‰ HEAD
            local_proc = await asyncio.create_subprocess_exec(
                "git", "rev-parse", "HEAD",
                cwd=str(settings.BASE_DIR), stdout=asyncio.subprocess.PIPE
            )
            l_out, _ = await local_proc.communicate()
            return False, l_out.decode().strip()[:8]
        except Exception as e:
            return False, f"Git æ£€æŸ¥å¤±è´¥: {e}"

    async def _check_via_http(self) -> Tuple[bool, str]:
        """é€šè¿‡ HTTP API æ£€æŸ¥æ›´æ–° (é’ˆå¯¹æ—  Git ç¯å¢ƒ)"""
        try:
            import httpx
            # å‡å®š GitHubï¼Œè·å–æœ€æ–°ç‰ˆæœ¬çš„ commit æˆ–è€…æ˜¯ç‰ˆæœ¬å·
            # è¿™é‡Œç®€å•èµ·è§ï¼Œå°è¯•è·å–ä¸»åˆ†æ”¯çš„ SHA
            repo_path = settings.UPDATE_REMOTE_URL.replace("https://github.com/", "").replace(".git", "")
            api_url = f"https://api.github.com/repos/{repo_path}/commits/{settings.UPDATE_BRANCH}"
            
            async with httpx.AsyncClient(timeout=10.0) as client:
                resp = await client.get(api_url)
                if resp.status_code == 200:
                    remote_sha = resp.json().get("sha", "")
                    # å¯¹æ¯”æœ¬åœ°å­˜å‚¨çš„ç‰ˆæœ¬ (åœ¨æ—  Git ç¯å¢ƒä¸‹ï¼Œæˆ‘ä»¬ä¾èµ– state æ–‡ä»¶è®°å½•å½“å‰ SHA)
                    state = self._get_state()
                    local_sha = state.get("current_version", "æœªçŸ¥")
                    
                    if remote_sha and remote_sha != local_sha:
                        return True, remote_sha[:8]
                    return False, local_sha[:8]
                else:
                    return False, f"HTTP è¯·æ±‚å¤±è´¥ ({resp.status_code})"
        except Exception as e:
            return False, f"HTTP æ£€æŸ¥å¼‚å¸¸: {e}"

    async def perform_update(self) -> Tuple[bool, str]:
        """æ‰§è¡Œç”Ÿäº§çº§åŸå­æ›´æ–°æµç¨‹"""
        if self._is_updating:
            return False, "å¹¶å‘é”: æ›´æ–°å·²åœ¨è¿›è¡Œä¸­"
        
        self._is_updating = True
        try:
            if self._git_available and self._is_git_repo:
                return await self._perform_git_update()
            else:
                return await self._perform_http_update()
        finally:
            self._is_updating = False

    async def _perform_git_update(self) -> Tuple[bool, str]:
        """æ‰§è¡Œ Git æ›´æ–°"""
        try:
            # 1. è®°å½•å½“å‰ç‰ˆæœ¬
            current_proc = await asyncio.create_subprocess_exec(
                "git", "rev-parse", "HEAD",
                cwd=str(settings.BASE_DIR), stdout=asyncio.subprocess.PIPE
            )
            c_out, _ = await current_proc.communicate()
            prev_version = c_out.decode().strip()

            # 2. æ£€æŸ¥ä¾èµ–æ–‡ä»¶ (requirements.txt) å“ˆå¸Œå€¼
            req_hash_before = self._get_file_hash(settings.BASE_DIR / "requirements.txt")

            # 3. æ‰§è¡Œå•å‘åŒæ­¥ (Hard Reset)
            # ç†ç”±ï¼šå½»åº•æ¶ˆé™¤ä»»ä½•æœ¬åœ°æƒé™æˆ–æ–‡ä»¶æ„å¤–æ”¹åŠ¨å¯¹æ›´æ–°çš„é˜»ç¢
            process = await asyncio.create_subprocess_exec(
                "git", "reset", "--hard", f"origin/{settings.UPDATE_BRANCH}",
                cwd=str(settings.BASE_DIR),
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            stdout, stderr = await process.communicate()
            
            if process.returncode != 0:
                return False, f"Git åŒæ­¥å¤±è´¥: {stderr.decode()}"

            # 4. ä¾èµ–é¡¹å¯¹é½
            req_hash_after = self._get_file_hash(settings.BASE_DIR / "requirements.txt")
            if req_hash_before != req_hash_after:
                logger.info("ğŸ“¦ [æ›´æ–°] æ£€æµ‹åˆ°ä¾èµ–æ–‡ä»¶å˜æ›´ï¼Œæ­£åœ¨é™é»˜åŒæ­¥åº“...")
                dep_success = await self._sync_dependencies()
                if not dep_success:
                    logger.warning("âš ï¸ ä¾èµ–åŒæ­¥å¤±è´¥ï¼Œå»ºè®®æ‰‹åŠ¨æ£€æŸ¥ requirements.txt ä»¥å…ç³»ç»Ÿå¯åŠ¨å¤±è´¥ã€‚")

            # 5. è·å–æ›´æ–°åçš„ç‰ˆæœ¬ ID å¹¶æŒä¹…åŒ–çŠ¶æ€
            new_proc = await asyncio.create_subprocess_exec(
                "git", "rev-parse", "HEAD",
                cwd=str(settings.BASE_DIR), stdout=asyncio.subprocess.PIPE
            )
            n_out, _ = await new_proc.communicate()
            current_id = n_out.decode().strip()

            state = self._get_state()
            state.update({
                "status": "restarting",
                "prev_version": prev_version,
                "current_version": current_id, # è®°å½•çœŸå®çš„ SHA ç”¨äºåç»­æ¯”å¯¹
                "timestamp": datetime.now().isoformat(),
                "fail_count": 0
            })
            self._save_state(state)
            
            return True, "Git ä»£ç åŸå­åŒæ­¥å®Œæˆ"
        except Exception as e:
            return False, f"Git æ›´æ–°æ‰§è¡Œå¼‚å¸¸: {e}"

    async def _perform_http_update(self) -> Tuple[bool, str]:
        """é€šè¿‡ä¸‹è½½å‹ç¼©åŒ…æ‰§è¡Œ HTTP æ›´æ–° (æ—  Git ç¯å¢ƒ fallback)"""
        try:
            import httpx
            import zipfile
            import shutil
            import io

            repo_path = settings.UPDATE_REMOTE_URL.replace("https://github.com/", "").replace(".git", "")
            zip_url = f"https://github.com/{repo_path}/archive/refs/heads/{settings.UPDATE_BRANCH}.zip"
            
            logger.info(f"æ­£åœ¨ä» HTTP ä¸‹è½½æ›´æ–°åŒ…: {zip_url}")
            # [å®‰å…¨] é™åˆ¶æœ€å¤§ä¸‹è½½å¤§å° (é˜²æ­¢ç‚¸å¼¹åŒ…)
            async with httpx.AsyncClient(timeout=60.0, follow_redirects=True) as client:
                resp = await client.get(zip_url)
                if resp.status_code != 200:
                    return False, f"ä¸‹è½½å¤±è´¥ ({resp.status_code})"
                
                # æ£€æŸ¥å†…å®¹ç±»å‹
                content_type = resp.headers.get("content-type", "")
                if "zip" not in content_type and "octet-stream" not in content_type:
                     return False, f"ä¸‹è½½å†…å®¹ç±»å‹å¼‚å¸¸: {content_type}"
                
                zip_data = io.BytesIO(resp.content)
                
            # å¤‡ä»½å½“å‰ç‰ˆæœ¬
            backup_path = await self._create_local_backup()
            state = self._get_state()
            prev_version = state.get("current_version", "æœªçŸ¥")

            with zipfile.ZipFile(zip_data) as z:
                # GitHub zip ç»“æ„é€šå¸¸æ˜¯: RepoName-BranchName/Files...
                root_dir = z.namelist()[0].split('/')[0]
                
                for member in z.namelist():
                    # [å®‰å…¨] é˜²æ­¢ Zip Slip æ¼æ´ (è·¯å¾„ç©¿è¶Šæ”»å‡»)
                    if '..' in member or member.startswith('/') or  '\\' in member:
                        logger.warning(f"âš ï¸ [å®‰å…¨æ‹¦æˆª] æ£€æµ‹åˆ°éæ³•æ–‡ä»¶è·¯å¾„: {member}")
                        continue

                    if member == root_dir + '/' or not member.startswith(root_dir + '/'):
                        continue
                    
                    filename = member.replace(root_dir + '/', '', 1)
                    if not filename: continue
                    
                    # ä¿æŠ¤æ’é™¤åå•
                    if any(filename.startswith(p) for p in [".env", "data/", "db/", "logs/", "temp/", ".git/"]):
                        continue
                    
                    target_path = settings.BASE_DIR / filename
                    
                    # å¦‚æœæ˜¯ç›®å½•ï¼Œåˆ›å»ºé€šè¿‡
                    if member.endswith('/'):
                        target_path.mkdir(parents=True, exist_ok=True)
                        continue

                    # ç¡®ä¿çˆ¶ç›®å½•å­˜åœ¨
                    target_path.parent.mkdir(parents=True, exist_ok=True)
                    
                    # Atomic Write with Retry (Windows Robustness)
                    for i in range(3):
                        try:
                            source = z.open(member)
                            with open(target_path, "wb") as f:
                                shutil.copyfileobj(source, f)
                            break
                        except PermissionError:
                            if i == 2: 
                                logger.error(f"æ— æ³•å†™å…¥æ–‡ä»¶ (è¢«å ç”¨): {filename}")
                                # è¿™é‡Œå¦‚æœå¤±è´¥ï¼Œå¯èƒ½å¯¼è‡´ä¸å®Œæ•´æ›´æ–°ã€‚ä½†æœ‰äº† backupï¼Œæˆ‘ä»¬å¯ä»¥å›æ»šã€‚
                                # æš‚æ—¶ç»§ç»­ï¼Œæˆ–æŠ›å‡ºå¼‚å¸¸è§¦å‘æ•´ä½“å¤±è´¥ï¼Ÿ
                                # è€ƒè™‘åˆ°åŸå­æ€§éš¾ä¿è¯ï¼ŒæŠ›å‡ºå¼‚å¸¸æ¯”è¾ƒå®‰å…¨
                                raise
                            await asyncio.sleep(0.5)
            
            # è·å–æœ€æ–°çš„ SHA ç”¨äºä¸‹æ¬¡å¯¹æ¯”
            _, remote_sha = await self._check_via_http()
            
            state.update({
                "status": "restarting",
                "prev_version": prev_version,
                "backup_file": str(backup_path) if backup_path else None,
                "current_version": remote_sha,
                "timestamp": datetime.now().isoformat(),
                "fail_count": 0
            })
            self._save_state(state)
            
            return True, "HTTP å¢é‡æ›´æ–°åŒæ­¥å®Œæˆ"
        except Exception as e:
            return False, f"HTTP æ›´æ–°å¼‚å¸¸: {e}"
        finally:
            self._is_updating = False

    def _get_file_hash(self, path: Path) -> str:
        """è·å–æ–‡ä»¶ MD5 å“ˆå¸Œ"""
        if not path.exists():
            return ""
        import hashlib
        try:
            return hashlib.md5(path.read_bytes()).hexdigest()
        except Exception as e:
            return ""

    async def _sync_dependencies(self) -> bool:
        """æ‰§è¡Œåå°ä¾èµ–å®‰è£… (ä½¿ç”¨ uv åŠ é€Ÿ)"""
        try:
            # ä¼˜å…ˆä½¿ç”¨ uv
            cmd = ["uv", "pip", "install", "--python", sys.executable, "-r", "requirements.txt"]
            
            process = await asyncio.create_subprocess_exec(
                *cmd,
                cwd=str(settings.BASE_DIR),
                stdout=asyncio.subprocess.DEVNULL,
                stderr=asyncio.subprocess.PIPE
            )
            _, stderr = await process.communicate()
            return process.returncode == 0
        except Exception:
            return False

    async def _create_local_backup(self) -> Optional[Path]:
        """ä¸º HTTP æ›´æ–°åˆ›å»ºæœ¬åœ°æ–‡ä»¶å¤‡ä»½ (Zip)"""
        import zipfile
        
        backup_dir = settings.BASE_DIR / "data" / "backups"
        backup_dir.mkdir(parents=True, exist_ok=True)
        
        timestamp = int(datetime.now().timestamp())
        backup_path = backup_dir / f"update_backup_{timestamp}.zip"
        
        try:
            with zipfile.ZipFile(backup_path, "w", zipfile.ZIP_DEFLATED) as z:
                # å¤‡ä»½æ ¸å¿ƒä»£ç ï¼Œæ’é™¤æ•°æ®æ–‡ä»¶
                for root, dirs, files in os.walk(settings.BASE_DIR):
                    # æ’é™¤ç›®å½•
                    dirs[:] = [d for d in dirs if d not in [".git", "__pycache__", "venv", ".venv", ".mypy_cache", ".pytest_cache", "logs", "temp", "data", "sessions", "db"]]
                    
                    for file in files:
                        if file.endswith((".pyc", ".db", ".sqlite", ".log", ".zip")):
                            continue
                            
                        file_path = Path(root) / file
                        arcname = file_path.relative_to(settings.BASE_DIR)
                        z.write(file_path, arcname)
                        
            logger.info(f"å·²åˆ›å»ºæœ¬åœ°å¤‡ä»½: {backup_path}")
            
            # æ—‹è½¬å¤‡ä»½
            self._rotate_backups(backup_dir, "update_backup_*.zip", settings.UPDATE_BACKUP_LIMIT)
            
            return backup_path
        except Exception as e:
            logger.error(f"åˆ›å»ºæœ¬åœ°å¤‡ä»½å¤±è´¥: {e}")
            return None

    def _rotate_backups(self, directory: Path, pattern: str, limit: int = 10):
        """æ—‹è½¬å¤‡ä»½æ–‡ä»¶ï¼Œä¿ç•™æœ€æ–°çš„ N ä¸ª"""
        try:
            if not directory.exists():
                return
            
            import glob
            # è·å–åŒ¹é… pattern çš„æ‰€æœ‰æ–‡ä»¶ï¼ŒæŒ‰ä¿®æ”¹æ—¶é—´é™åºæ’åº
            file_list = sorted(
                glob.glob(str(directory / pattern)),
                key=os.path.getmtime,
                reverse=True
            )
            
            if len(file_list) > limit:
                to_delete = file_list[limit:]
                logger.info(f"ğŸ§¹ [æ›´æ–°] å‘ç°å¤‡ä»½è¶…é™ ({len(file_list)} > {limit})ï¼Œæ­£åœ¨æ¸…ç†æ—§å¤‡ä»½ {pattern}...")
                for f in to_delete:
                    try:
                        os.remove(f)
                        logger.debug(f"å·²åˆ é™¤æ—§å¤‡ä»½: {os.path.basename(f)}")
                    except Exception as e:
                        logger.warning(f"åˆ é™¤ç‰©ç†æ–‡ä»¶å¤±è´¥: {f}, é”™è¯¯: {e}")
        except Exception as e:
            logger.error(f"æ—‹è½¬å¤‡ä»½å¤±è´¥: {e}")

    async def _restore_from_local_backup(self, backup_path_str: str) -> Tuple[bool, str]:
        """ä»æœ¬åœ° Zip å¤‡ä»½è¿˜åŸ"""
        import zipfile
        import shutil
        
        backup_path = Path(backup_path_str)
        if not backup_path.exists():
            return False, "å¤‡ä»½æ–‡ä»¶å·²ä¸å­˜åœ¨"
            
        try:
            logger.info(f"æ­£åœ¨ä»å¤‡ä»½è¿˜åŸ: {backup_path}")
            
            # è§£å‹è¿˜åŸ
            with zipfile.ZipFile(backup_path, 'r') as z:
                for member in z.namelist():
                     # å®‰å…¨æ£€æŸ¥
                    if '..' in member or member.startswith('/') or  '\\' in member:
                        continue
                        
                    target = settings.BASE_DIR / member
                    
                    if member.endswith('/'):
                        target.mkdir(parents=True, exist_ok=True)
                    else:
                        target.parent.mkdir(parents=True, exist_ok=True)
                        # é‡è¯•é€»è¾‘ç”¨äº Windows æ–‡ä»¶å ç”¨
                        for i in range(3):
                            try:
                                with z.open(member) as source, open(target, "wb") as dest:
                                    shutil.copyfileobj(source, dest)
                                break
                            except PermissionError:
                                if i == 2: raise
                                await asyncio.sleep(0.5)
                                
            return True, "å·²æˆåŠŸä»æœ¬åœ°å¤‡ä»½è¿˜åŸ"
        except Exception as e:
            return False, f"è¿˜åŸå¤±è´¥: {e}"

    async def rollback(self) -> Tuple[bool, str]:
        """æ‰§è¡Œç´§æ€¥å›æ»šæµç¨‹ (æ”¯æŒ Git å’Œ HTTP)"""
        state = self._get_state()
        
        # 1. å¦‚æœæœ‰ Git
        if self._git_available and self._is_git_repo:
            prev = state.get("prev_version")
            if not prev:
                return False, "æœªæ‰¾åˆ°æœ‰æ•ˆçš„ Git ç‰ˆæœ¬è®°å½•"
            
            logger.critical(f"ğŸš‘ [å›æ»š] Git Reset è‡³: {prev[:8]}...")
            process = await asyncio.create_subprocess_exec(
                "git", "reset", "--hard", prev,
                cwd=str(settings.BASE_DIR)
            )
            await process.wait()
            if process.returncode == 0:
                # æ¸…ç†é”æ–‡ä»¶
                for f in ["UPDATE_LOCK.json", "UPDATE_VERIFYING.json"]:
                    lock_f = settings.BASE_DIR / "data" / f
                    if lock_f.exists(): lock_f.unlink()
            return process.returncode == 0, f"Git å›æ»šè‡³ {prev[:8]}"
            
        # 2. å¦‚æœæ˜¯ HTTP æ¨¡å¼
        else:
            backup_file = state.get("backup_file")
            if not backup_file:
                return False, "æœªæ‰¾åˆ° HTTP æ›´æ–°çš„æœ¬åœ°å¤‡ä»½æ–‡ä»¶"
            
            logger.critical(f"ğŸš‘ [å›æ»š] æ­£åœ¨è¿˜åŸå¤‡ä»½åŒ…: {Path(backup_file).name}...")
            success, msg = await self._restore_from_local_backup(backup_file)
            if success:
                for f in ["UPDATE_LOCK.json", "UPDATE_VERIFYING.json"]:
                    lock_f = settings.BASE_DIR / "data" / f
                    if lock_f.exists(): lock_f.unlink()
            return success, msg

    def stop(self):
        """åœæ­¢æ›´æ–°ç›‘æ§å¹¶æ¸…ç†ä»»åŠ¡"""
        self._stop_event.set()
        # æ˜¾å¼å–æ¶ˆä»»åŠ¡
        for t in self._tasksList:
            if not t.done():
                t.cancel()
        self._tasksList.clear()
        logger.info("UpdateService ä»»åŠ¡å·²æ¸…ç†")

# å…¨å±€å•ä¾‹
update_service = UpdateService()
