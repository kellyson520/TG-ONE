from sqlalchemy import select, update, func
from models.models import TaskQueue, ForwardRule, Chat
from datetime import datetime, timedelta
import logging
from core.states import validate_transition
from core.config import settings

logger = logging.getLogger(__name__)

class TaskRepository:
    def __init__(self, db):
        self.db = db

    async def push(self, task_type: str, payload: dict, priority: int = 0, scheduled_at: datetime = None):
        import json
        from sqlalchemy import insert
        
        # æå–ç”¨äºå»é‡çš„å…³é”®ä¿¡æ¯
        chat_id = payload.get('chat_id')
        message_id = payload.get('message_id')
        grouped_id = payload.get('grouped_id')
        
        unique_key = None
        if chat_id and message_id:
            unique_key = f"{task_type}:{chat_id}:{message_id}"

        from core.db_factory import AsyncSessionManager
        async with AsyncSessionManager() as session:
            # [Scheme 7 Optimization] ä½¿ç”¨åŸå­åŒ– INSERT OR IGNORE æ›¿ä»£å…ˆæŸ¥åå¢
            # å½»åº•è§£å†³å¤šå¹¶å‘åœºæ™¯ä¸‹çš„é‡å¤æ¨é€é—®é¢˜
            stmt = insert(TaskQueue).values(
                task_type=task_type,
                task_data=json.dumps(payload),
                unique_key=unique_key,
                grouped_id=str(grouped_id) if grouped_id else None,
                priority=priority,
                status='pending',
                scheduled_at=scheduled_at,
                created_at=datetime.utcnow(),
                updated_at=datetime.utcnow()
            ).prefix_with('OR IGNORE')
            
            result = await session.execute(stmt)
            await session.commit()
            
            if result.rowcount > 0:
                logger.info(f"âœ… ä»»åŠ¡å…¥åˆ—æˆåŠŸ (Key: {unique_key})")
            else:
                if unique_key:
                    logger.warning(f"âš ï¸ ä»»åŠ¡å·²å­˜åœ¨ï¼Œè·³è¿‡å…¥åˆ—: {unique_key}")
                else:
                    logger.warning("âš ï¸ ä»»åŠ¡å…¥åˆ—è¢«å¿½ç•¥ (rowcount=0)")

    async def push_batch(self, tasks_data: list):
        """
        æ‰¹é‡å†™å…¥ä»»åŠ¡ (Batch Insert)
        Args:
            tasks_data: List[(task_type, payload, priority)]
        """
        import json
        from sqlalchemy import insert
        
        if not tasks_data:
            return
            
        values_list = []
        now = datetime.utcnow()
        
        for task_type, payload, priority in tasks_data:
            chat_id = payload.get('chat_id')
            message_id = payload.get('message_id')
            grouped_id = payload.get('grouped_id')
            
            unique_key = None
            if chat_id and message_id:
                unique_key = f"{task_type}:{chat_id}:{message_id}"
            
            values_list.append({
                "task_type": task_type,
                "task_data": json.dumps(payload),
                "unique_key": unique_key,
                "grouped_id": str(grouped_id) if grouped_id else None,
                "priority": priority,
                "attempts": 0,
                "status": "pending",
                "created_at": now,
                "updated_at": now
            })

        if not values_list:
            return

        from core.db_factory import AsyncSessionManager
        async with AsyncSessionManager() as session:
             # ä½¿ç”¨ Core Insert + OR IGNORE (SQLite) å®ç°é«˜æ€§èƒ½æ‰¹é‡å»é‡å†™å…¥
             try:
                 stmt = insert(TaskQueue).values(values_list).prefix_with('OR IGNORE')
                 await session.execute(stmt)
                 # AsyncSessionManager handles commit automatically
                 logger.info(f"âœ… æ‰¹é‡èšåˆå†™å…¥: {len(values_list)} æ¡ä»»åŠ¡")
             except Exception as e:
                 logger.error(f"æ‰¹é‡å†™å…¥å¤±è´¥: {e}")
                 # Fallback: å¦‚æœæ‰¹é‡å¤±è´¥ï¼ˆç½•è§ï¼‰ï¼Œå¯ä»¥è€ƒè™‘é€æ¡é‡è¯•ï¼Œæˆ–è€…ç›´æ¥æŠ›å‡º
                 raise

    async def fetch_next(self, limit: int = 1):
        """[Scheme 7 Standard] åŸå­åŒ–æ‹‰å–ä»»åŠ¡ (æ”¯æŒåª’ä½“ç»„èšåˆä¸æ‰¹é‡æ‹‰å–)
        ä½¿ç”¨ UPDATE ... RETURNING ç¡®ä¿å–å‡ºä»»åŠ¡çš„åŒæ—¶é”å®šçŠ¶æ€ã€‚
        å¦‚æœä»»åŠ¡å±äºåª’ä½“ç»„ï¼Œåˆ™åŸå­åŒ–é”å®šè¯¥ç»„å†…æ‰€æœ‰ 'pending' ä»»åŠ¡ï¼Œ
        å½»åº•æ ¹é™¤å¤š Worker å¹¶å‘ä¸‹çš„ç«æ€æ¡ä»¶ã€‚
        """
        from core.db_factory import AsyncSessionManager
        async with AsyncSessionManager() as session:
            # [Optimization] å¢åŠ  30s æ—¶é—´å†—ä½™
            now = datetime.utcnow()
            buffer_now = now + timedelta(seconds=30)
            # å®šä¹‰ç§Ÿçº¦æœ‰æ•ˆæœŸï¼ˆVisibility Timeoutï¼‰ï¼š15 åˆ†é’Ÿ
            lease_duration = timedelta(minutes=15)
            lease_until = now + lease_duration
            
            # 1. å®šä½å€™é€‰ä»»åŠ¡ ID åˆ—è¡¨ (å– limit ä¸ª)
            candidate_ids_sub = (
                select(TaskQueue.id)
                .where(
                    (TaskQueue.status == 'pending') |
                    (
                        (TaskQueue.status == 'running') & 
                        (TaskQueue.locked_until != None) & 
                        (TaskQueue.locked_until <= now)
                    )
                )
                .where((TaskQueue.scheduled_at == None) | (TaskQueue.scheduled_at <= buffer_now))
                .where((TaskQueue.next_retry_at == None) | (TaskQueue.next_retry_at <= buffer_now))
                .order_by(TaskQueue.priority.desc(), TaskQueue.created_at.asc())
                .limit(limit)
                .scalar_subquery()
            )

            # 2. è·å–è¿™äº›ä»»åŠ¡å…³è”çš„å…¨éƒ¨ grouped_id
            target_groups_sub = (
                select(TaskQueue.grouped_id)
                .where(TaskQueue.id.in_(candidate_ids_sub))
                .where(TaskQueue.grouped_id != None)
                .scalar_subquery()
            )

            # 3. åŸå­æ‰§è¡Œï¼šé”å®šé€‰ä¸­çš„ä»»åŠ¡åŠå…¶æ‰€å±çš„åª’ä½“ç»„ä»»åŠ¡
            stmt = (
                update(TaskQueue)
                .where(
                    (TaskQueue.id.in_(candidate_ids_sub)) |
                    (
                        (
                            (TaskQueue.status == 'pending') |
                            ((TaskQueue.status == 'running') & (TaskQueue.locked_until <= now))
                        ) &
                        (TaskQueue.grouped_id != None) &
                        (TaskQueue.grouped_id.in_(target_groups_sub))
                    )
                )
                .values(
                    status='running',
                    started_at=now,
                    locked_until=lease_until, # è®¾ç½®ç§Ÿçº¦ï¼Œé˜²æ­¢åƒµå°¸åŒ–
                    updated_at=now
                )
                .execution_options(synchronize_session=False)
                .returning(TaskQueue)
            )

            result = await session.execute(stmt)
            tasks = result.scalars().all()
            
            if tasks:
                # AsyncSessionManager will commit automatically on __aexit__
                # æ’åºï¼šç¡®ä¿æœ€æ—©çš„ä»»åŠ¡æ”¾åœ¨å‰åˆ—
                tasks.sort(key=lambda x: x.created_at)
                logger.debug(f"ğŸ”’ åŸå­æ‰¹é‡é”å®šæˆåŠŸ: è·å–åˆ° {len(tasks)} ä¸ªä»»åŠ¡ (IDs: {[t.id for t in tasks]})")
                return tasks
            
            return []

    async def complete(self, task_id: int):
        async with self.db.get_session() as session:
            # å…ˆè·å–å½“å‰çŠ¶æ€è¿›è¡ŒéªŒè¯
            result = await session.execute(
                select(TaskQueue.status).where(TaskQueue.id == task_id)
            )
            current_status = result.scalar_one_or_none()
            
            if current_status and validate_transition(current_status, 'completed'):
                now = datetime.utcnow()
                await session.execute(
                    update(TaskQueue).where(TaskQueue.id == task_id).values(
                        status='completed',
                        completed_at=now,
                        updated_at=now
                    )
                )
                await session.commit()
                logger.info(f"ä»»åŠ¡å®Œæˆ: {task_id}")
            else:
                logger.warning(f"Invalid state transition for task {task_id}: {current_status} -> completed")

    async def fail(self, task_id: int, error: str):
        async with self.db.get_session() as session:
            # å…ˆè·å–å½“å‰çŠ¶æ€è¿›è¡ŒéªŒè¯
            result = await session.execute(
                select(TaskQueue.status).where(TaskQueue.id == task_id)
            )
            current_status = result.scalar_one_or_none()
            
            if current_status and validate_transition(current_status, 'failed'):
                now = datetime.utcnow()
                await session.execute(
                    update(TaskQueue).where(TaskQueue.id == task_id).values(
                        status='failed', 
                        error_message=str(error),
                        updated_at=now
                    )
                )
                await session.commit()
                
                # å¯¹äº "Source message not found" è¿™ç±»é¢„æœŸå†…çš„ä¸šåŠ¡æƒ…å†µ,ä½¿ç”¨ DEBUG çº§åˆ«
                # é¿å…è§¦å‘é”™è¯¯å‘Šè­¦å’Œæ—¥å¿—å¾ªç¯
                if "Source message not found" in str(error):
                    logger.debug(f"ä»»åŠ¡å¤±è´¥: {task_id}, é”™è¯¯: {error}")
                else:
                    logger.error(f"ä»»åŠ¡å¤±è´¥: {task_id}, é”™è¯¯: {error}")
            else:
                logger.warning(f"Invalid state transition for task {task_id}: {current_status} -> failed")
            
    async def fail_or_retry(self, task_id: int, error: str, max_retries: int = settings.MAX_RETRIES):
        """æ ¸å¿ƒä¿®å¤ï¼šå¤±è´¥é‡è¯•æœºåˆ¶"""
        async with self.db.get_session() as session:
            stmt = select(TaskQueue).where(TaskQueue.id == task_id)
            result = await session.execute(stmt)
            task = result.scalar_one_or_none()
            
            if task:
                now = datetime.utcnow()
                task.error_message = str(error)
                if task.attempts < max_retries:
                    if validate_transition(task.status, 'pending'):
                        task.attempts += 1
                        task.status = 'pending' # é‡æ–°æ”¾å›é˜Ÿåˆ—
                        task.priority += 1      # ç¨å¾®æé«˜ä¼˜å…ˆçº§ä»¥ä¾¿é‡è¯•
                        # å®ç°æŒ‡æ•°é€€é¿ç®—æ³•ï¼š2^(attempts) ç§’
                        backoff_seconds = 2 ** task.attempts
                        task.next_retry_at = now + timedelta(seconds=backoff_seconds)
                        task.updated_at = now
                        logger.info(f"ä»»åŠ¡é‡è¯•: {task_id}, é‡è¯•æ¬¡æ•°: {task.attempts}, ä¸‹æ¬¡é‡è¯•æ—¶é—´: {task.next_retry_at}")
                else:
                    if validate_transition(task.status, 'failed'):
                        task.status = 'failed'  # å½»åº•å¤±è´¥
                        task.updated_at = now
                        logger.error(f"ä»»åŠ¡æœ€ç»ˆå¤±è´¥: {task_id}, é”™è¯¯: {error}")
                await session.commit()
            
    async def rescue_stuck_tasks(self, timeout_minutes: int = 10):
        """åƒµå°¸ä»»åŠ¡æ•‘æ´ - å°†å¤„äº 'running' çŠ¶æ€è¶…è¿‡æŒ‡å®šæ—¶é—´çš„ä»»åŠ¡é‡ç½®ä¸º 'pending'"""
        from core.db_factory import AsyncSessionManager
        async with AsyncSessionManager() as session:
            cutoff_time = datetime.utcnow() - timedelta(minutes=timeout_minutes)
            now = datetime.utcnow()
            
            # æŸ¥æ‰¾å¹¶é‡ç½®åƒµå°¸ä»»åŠ¡
            # åªå¯¹çŠ¶æ€ä¸ºrunningä¸”æ›´æ–°æ—¶é—´è¶…è¿‡cutoff_timeçš„ä»»åŠ¡è¿›è¡Œæ“ä½œ
            stmt = update(TaskQueue).where(
                TaskQueue.status == 'running',
                TaskQueue.updated_at < cutoff_time
            ).values(
                status='pending',
                attempts=TaskQueue.attempts + 1, # å¢åŠ é‡è¯•è®¡æ•°
                error_message=TaskQueue.error_message + ' [System] Task rescued from zombie state',
                updated_at=now
            )
            
            result = await session.execute(stmt)
            await session.commit()
            
            if result.rowcount > 0:
                logger.info(f"å·²æ•‘æ´ {result.rowcount} ä¸ªåƒµå°¸ä»»åŠ¡")
            return result.rowcount
            
    async def reschedule(self, task_id: int, next_run_time: datetime):
        """é‡æ–°è°ƒåº¦ä»»åŠ¡ï¼Œè®¾ç½®ä¸‹æ¬¡æ‰§è¡Œæ—¶é—´"""
        async with self.db.get_session() as session:
            # å…ˆè·å–å½“å‰çŠ¶æ€è¿›è¡ŒéªŒè¯
            result = await session.execute(
                select(TaskQueue.status).where(TaskQueue.id == task_id)
            )
            current_status = result.scalar_one_or_none()
            
            if current_status and validate_transition(current_status, 'pending'):
                now = datetime.utcnow()
                await session.execute(
                    update(TaskQueue).where(TaskQueue.id == task_id).values(
                        status='pending',
                        scheduled_at=next_run_time,
                        next_retry_at=next_run_time,  # æ›´æ–°ä¸‹æ¬¡é‡è¯•æ—¶é—´
                        updated_at=now
                    )
                )
                await session.commit()
                logger.info(f"ä»»åŠ¡é‡æ–°è°ƒåº¦: {task_id}, ä¸‹æ¬¡æ‰§è¡Œæ—¶é—´: {next_run_time}")
            else:
                logger.warning(f"Invalid state transition for task {task_id}: {current_status} -> pending (reschedule)")

    async def fetch_group_tasks(self, grouped_id: str, exclude_task_id: int):
        """
        è·å–åŒä¸€åª’ä½“ç»„çš„å…¶ä»–ç›¸å…³ä»»åŠ¡ï¼Œå¹¶åŸå­é”å®šå®ƒä»¬
        
        Args:
            grouped_id: åª’ä½“ç»„ID
            exclude_task_id: å½“å‰å·²è·å–çš„ä»»åŠ¡IDï¼ˆæ’é™¤å®ƒï¼‰
            
        Returns:
            List[TaskQueue]: ç›¸å…³ä»»åŠ¡åˆ—è¡¨
        """
        from core.db_factory import AsyncSessionManager
        async with AsyncSessionManager() as session:
            # [Optimization] å¢åŠ  30s æ—¶é—´å†—ä½™ï¼Œå½»åº•æ ¹é™¤æ—¶é’Ÿåå·®å¯¼è‡´çš„ä»»åŠ¡"ä¸å¯è§"é—®é¢˜
            now = datetime.utcnow() + timedelta(seconds=30)
            
            # 1. æŸ¥æ‰¾åŒç»„çš„å…¶ä»– pending ä»»åŠ¡
            stmt = (
                select(TaskQueue.id)
                .where(TaskQueue.grouped_id == grouped_id)
                .where(TaskQueue.id != exclude_task_id)
                .where(TaskQueue.status == 'pending')  # åªè·å– pending çš„
                .order_by(TaskQueue.id.asc())
            )
            result = await session.execute(stmt)
            task_ids = result.scalars().all()
            
            if not task_ids:
                return []
                
            # 2. åŸå­é”å®šè¿™äº›ä»»åŠ¡
            update_stmt = (
                update(TaskQueue)
                .where(TaskQueue.id.in_(task_ids))
                .values(
                    status='running',
                    started_at=now,
                    updated_at=now
                )
                .execution_options(synchronize_session=False)
                .returning(TaskQueue)
            )
            
            result = await session.execute(update_stmt)
            tasks = result.scalars().all()
            
            await session.commit()
            logger.info(f"ğŸ”’ åŸå­é”å®šå¹¶è·å–åª’ä½“ç»„ä»»åŠ¡: {len(tasks)} ä¸ª (Group: {grouped_id})")
            return tasks

    async def get_queue_status(self):
        """è·å–é˜Ÿåˆ—çŠ¶æ€ç»Ÿè®¡"""
        async with self.db.get_session() as session:
            # è·å–å„çŠ¶æ€ä»»åŠ¡æ•°é‡
            pending_count = await session.execute(
                select(func.count()).where(TaskQueue.status == 'pending')
            )
            completed_count = await session.execute(
                select(func.count()).where(TaskQueue.status == 'completed')
            )
            failed_count = await session.execute(
                select(func.count()).where(TaskQueue.status == 'failed')
            )
            total_count = await session.execute(
                select(func.count(TaskQueue.id))
            )
            
            pending = pending_count.scalar() or 0
            completed = completed_count.scalar() or 0
            failed = failed_count.scalar() or 0
            total = total_count.scalar() or 0
            
            # è®¡ç®—é”™è¯¯ç‡
            err_rate = 0.0
            if completed + failed > 0:
                err_rate = (failed / (completed + failed)) * 100
            
            return {
                'active_queues': pending,
                'total_tasks': total,
                'completed_tasks': completed,
                'failed_tasks': failed,
                'error_rate': f"{err_rate:.1f}%"
            }

    async def get_rule_stats(self):
        """è·å–è§„åˆ™ç»Ÿè®¡ä¿¡æ¯"""
        async with self.db.get_session() as session:
            # è·å–æ€»è§„åˆ™æ•°å’Œæ´»è·ƒè§„åˆ™æ•°
            total_rules = await session.execute(
                select(func.count(ForwardRule.id))
            )
            active_rules = await session.execute(
                select(func.count(ForwardRule.id)).where(ForwardRule.enable_rule == True)
            )
            total_chats = await session.execute(
                select(func.count(Chat.id))
            )
            
            return {
                'total_rules': total_rules.scalar() or 0,
                'active_rules': active_rules.scalar() or 0,
                'total_chats': total_chats.scalar() or 0
            }

    async def get_tasks(self, page: int = 1, limit: int = 50, status: str = None):
        """åˆ†é¡µè·å–ä»»åŠ¡åˆ—è¡¨"""
        async with self.db.get_session() as session:
            # æ„å»ºæŸ¥è¯¢
            stmt = select(TaskQueue)
            if status:
                stmt = stmt.where(TaskQueue.status == status)
            
            # è®¡ç®—æ€»æ•°
            count_stmt = select(func.count()).select_from(stmt.subquery())
            total = (await session.execute(count_stmt)).scalar() or 0
            
            # æ’åºå’Œåˆ†é¡µ
            stmt = stmt.order_by(TaskQueue.priority.desc(), TaskQueue.created_at.desc())
            stmt = stmt.offset((page - 1) * limit).limit(limit)
            
            result = await session.execute(stmt)
            tasks = result.scalars().all()
            
            return tasks, total