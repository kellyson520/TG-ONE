from core.pipeline import Middleware
from services.dedup_service import dedup_service # å¤ç”¨ç°æœ‰æœåŠ¡

class DedupMiddleware(Middleware):
    async def process(self, ctx, next_call):
        # å¯¹æ¯æ¡å¯ç”¨çš„è§„åˆ™è¿›è¡Œå»é‡æ£€æŸ¥
        valid_rules = []
        recorded_targets = [] # Tuple(target_id, rule_id)
        import logging
        logger = logging.getLogger(__name__)

        for rule in ctx.rules:
            target_id = None
            if rule.target_chat:
                target_id = int(rule.target_chat.telegram_chat_id)
            
            # å¦‚æœè§„åˆ™å¼€å¯äº†å»é‡
            if rule.enable_dedup and target_id:
                logger.info(f"ğŸ” [Pipeline-Dedup] æ­£åœ¨æ£€æŸ¥å»é‡: è§„åˆ™ID={rule.id}, ç›®æ ‡ChatID={target_id}")
                
                # è§£æå•æ¡è§„åˆ™çš„è‡ªå®šä¹‰é…ç½® (JSON)
                rule_config = {}
                if rule.custom_config:
                    try:
                        import json
                        cfg = json.loads(rule.custom_config)
                        # ä»…æå–å»é‡ç›¸å…³é…ç½®
                        dedup_keys = {"similarity_threshold", "time_window_hours", "enable_smart_similarity", "enable_content_hash", "enable_sticker_filter", "sticker_strict_mode"}
                        for k in dedup_keys:
                            if k in cfg: rule_config[k] = cfg[k]
                    except Exception as e:
                        logger.warning(f"Failed to parse rule custom_config: {e}")

                # Optimistic Dedup: Check AND tentative record (Lock)
                # æ³¨å…¥å•æ¡è§„åˆ™é…ç½®
                is_dup, reason = await dedup_service.check_and_lock(target_id, ctx.message_obj, rule_config=rule_config)
                
                if is_dup:
                    logger.info(f"ğŸš« [Pipeline-Dedup] å‘ç°é‡å¤æ¶ˆæ¯ï¼Œè·³è¿‡è§„åˆ™: è§„åˆ™ID={rule.id}, åŸå› ={reason}")
                    continue # è·³è¿‡æ­¤è§„åˆ™
                
                # è®°å½•ä»¥ä¾¿å›æ»š
                recorded_targets.append((target_id, rule.id))
            
            valid_rules.append(rule)
        
        ctx.rules = valid_rules
        
        if ctx.rules:
            try:
                await next_call()
                
                # Post-processing Rollback Check
                # Check for specific failed rules reported by downstream
                if hasattr(ctx, 'failed_rules') and ctx.failed_rules:
                    for target_id, rule_id in recorded_targets:
                        if rule_id in ctx.failed_rules:
                            logger.info(f"âª [Pipeline-Dedup] è§„åˆ™ {rule_id} æ‰§è¡Œå¤±è´¥ï¼Œå›æ»šå»é‡çŠ¶æ€")
                            await dedup_service.rollback(target_id, ctx.message_obj)
                            
            except Exception as e:
                # Global Failure Rollback
                logger.error(f"âŒ [Pipeline-Dedup] ä¸‹æ¸¸å¤„ç†å¼‚å¸¸ï¼Œæ‰§è¡Œå…¨é¢å›æ»š: {e}")
                for target_id, rule_id in recorded_targets:
                    await dedup_service.rollback(target_id, ctx.message_obj)
                raise e
        else:
            logger.info(f"âš ï¸ [Pipeline-Dedup] æ‰€æœ‰è§„åˆ™å‡è¢«å»é‡è¿‡æ»¤ï¼Œæµç¨‹ç»“æŸ")