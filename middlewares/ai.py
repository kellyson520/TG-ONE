from core.pipeline import Middleware, MessageContext
from ai import get_ai_provider # å‡è®¾ ai/__init__.py æš´éœ²äº†è¿™ä¸ªå·¥å‚å‡½æ•°
import logging

logger = logging.getLogger(__name__)

class AIMiddleware(Middleware):
    async def process(self, ctx: MessageContext, next_call):
        # 1. æ£€æŸ¥æ˜¯å¦æœ‰è§„åˆ™å¯ç”¨äº† AI
        # æˆ‘ä»¬éœ€è¦éå†è§„åˆ™ï¼Œçœ‹çœ‹æœ‰æ²¡æœ‰éœ€è¦ AI å¤„ç†çš„ï¼ˆæ¯”å¦‚æ‘˜è¦ã€ç¿»è¯‘ï¼‰
        ai_rules = [r for r in ctx.rules if r.is_summary or r.is_ai]
        
        if not ai_rules:
            await next_call()
            return

        # 2. æå–æ–‡æœ¬å†…å®¹ (å¦‚æœæ²¡æœ‰æ–‡æœ¬ä¸”ä¸æ˜¯OCRåœºæ™¯ï¼Œåˆ™è·³è¿‡)
        text = ctx.message_obj.text
        if not text:
            await next_call()
            return

        # 3. æ‰§è¡Œ AI å¤„ç†
        # æ³¨æ„ï¼šè¿™é‡Œå¯èƒ½å¾ˆæ…¢ï¼Œä½†å› ä¸ºæ˜¯ Worker åœ¨è·‘ï¼Œä¸ä¼šé˜»å¡æ¥æ”¶
        try:
            # å‡è®¾æ‰€æœ‰è§„åˆ™ç”¨åŒä¸€ä¸ªæ¨¡å‹ï¼Œæˆ–è€…å–ç¬¬ä¸€ä¸ªé…ç½®
            # æ›´ç²¾ç»†çš„é€»è¾‘æ˜¯ï¼šé’ˆå¯¹ä¸åŒè§„åˆ™åšä¸åŒå¤„ç†ï¼Œè¿™é‡Œç®€åŒ–ä¸ºé€šç”¨æ‘˜è¦
            model_name = ai_rules[0].ai_model or "gpt-3.5-turbo"
            prompt = ai_rules[0].ai_prompt or "è¯·æ€»ç»“ä»¥ä¸‹å†…å®¹ï¼š"
            
            provider = await get_ai_provider(model_name)
            
            # è°ƒç”¨ AI (å‡è®¾ provider æ˜¯å¼‚æ­¥çš„ï¼Œæˆ–è€…ç”¨ run_in_executor åŒ…è£…)
            summary = await provider.process_message(text, prompt=prompt)
            
            # 4. å°†ç»“æœæŒ‚è½½åˆ° Context Metadata
            # ä¸‹æ¸¸çš„ SenderMiddleware å¯ä»¥è¯»å–è¿™ä¸ª metadata å‘é€æ‘˜è¦
            # åŒæ—¶å†™å…¥é€šç”¨ key ä½œä¸ºå…œåº•ï¼Œç¡®ä¿ä¸ SenderMiddleware æ‰€éœ€çš„ modified_text å¯¹é½
            for rule in ai_rules:
                ctx.metadata['ai_summary'] = summary
                ctx.metadata[f'modified_text_{rule.id}'] = summary
                logger.info(f"ğŸ¤– AI å¤„ç†å®Œæˆ (Rule {rule.id}): {summary[:30]}...")
            
            # å†™å…¥é€šç”¨ key ä½œä¸ºå…œåº•
            ctx.metadata['modified_text'] = summary
            
            # å¦‚æœè§„åˆ™æ˜¯â€œåªå‘æ‘˜è¦â€ï¼Œå¯èƒ½éœ€è¦ä¿®æ”¹ ctx.message_obj.text
            # ctx.message_obj.message = summary 
            
        except Exception as e:
            logger.error(f"AI processing failed: {e}")
            # AI å¤±è´¥é€šå¸¸ä¸åº”é˜»æ–­è½¬å‘ï¼Œç»§ç»­
            
        await next_call()
